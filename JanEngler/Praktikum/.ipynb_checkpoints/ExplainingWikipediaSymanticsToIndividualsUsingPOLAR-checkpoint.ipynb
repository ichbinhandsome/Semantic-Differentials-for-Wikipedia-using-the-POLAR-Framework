{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forschungspraktikum SS20 \n",
    "# Semantic Differentials for Wikipedia using the POLAR Framework\n",
    "\n",
    "\n",
    "The POLAR Framework is a method that enables Interpretability for pre-trained word embeddings. The goal of this project is to produce word embeddings from a Wikipedia dataset, and deploy the POLAR framework to different categories of words (e.g. Countries, Politicians, Music, etc) in order to explain the semantic associations behind concepts on Wikipedia. An evaluation setup should assess the quality of the semantic differentials produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from gensim.corpora.wikicorpus import WikiCorpus #https://radimrehurek.com/gensim/corpora/wikicorpus.html\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "# for 2d visalization (def display_closestwords_tsnescatterplot):\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#From Polar\n",
    "import gensim\n",
    "from numpy import linalg\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# progress bar for .ipyth \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from random import shuffle\n",
    "import sys\n",
    "import nltk \n",
    "from nltk.corpus import wordnet \n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "#%load_ext autotime\n",
    "\n",
    "import subprocess\n",
    "#for saving and loading vectors/lists on disk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Antonyms into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAntonyms(model,loadMusicAntonyms, loadCountryAntonyms,loadStandardAntonyms,loadFoodAntonyms): \n",
    "    current_model=model #= word2vec\n",
    "    list_antonym = []\n",
    "    if loadFoodAntonyms== True:    \n",
    "        with open(r'Antonym_sets/food50.txt') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[1]!=' ':\n",
    "                    word1 = parts[0]\n",
    "                    word2 = parts[1]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "\n",
    "    if loadCountryAntonyms== True:    \n",
    "        with open(r'Antonym_sets/country50.txt') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[1]!=' ':\n",
    "                    word1 = parts[0]\n",
    "                    word2 = parts[1]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "    if loadMusicAntonyms== True:\n",
    "        with open(r'Antonym_sets/music50.txt') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[0]!=' ':\n",
    "                    word1 = parts[0]\n",
    "                    word2 = parts[1]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "                        \n",
    "#POLAR Framework code (https://github.com/Sandipan99/POLAR)\n",
    "    if loadStandardAntonyms==True:\n",
    "        with open(r'Antonym_sets/LenciBenotto.val') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[3]=='antonym':\n",
    "                    word1 = parts[0].split('-')[0]\n",
    "                    word2 = parts[1].split('-')[0]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "\n",
    "        with open(r'Antonym_sets/LenciBenotto.test') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[3]=='antonym':\n",
    "                    word1 = parts[0].split('-')[0]\n",
    "                    word2 = parts[1].split('-')[0]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "        with open(r'Antonym_sets/EVALution.val') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[3]=='antonym':\n",
    "                    word1 = parts[0].split('-')[0]\n",
    "                    word2 = parts[1].split('-')[0]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "        with open(r'Antonym_sets/EVALution.test') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[3]=='antonym':\n",
    "                    word1 = parts[0].split('-')[0]\n",
    "                    word2 = parts[1].split('-')[0]\n",
    "                    if word1 in current_model and word2 in current_model:\n",
    "                        list_antonym.append((word1.strip().lower(), word2.strip().lower()))\n",
    "\n",
    "\n",
    "    list_antonym = list(dict.fromkeys(list_antonym).keys())\n",
    "    return list_antonym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing similarty between Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLAR Framework code (https://github.com/Sandipan99/POLAR) :\n",
    "def computeFinalAntonymsSimilariy(list_antonym): \n",
    "    similarity_matrix = defaultdict(list)\n",
    "    #pre processing of antonyms\n",
    "    for each_pair in tqdm(list_antonym):\n",
    "        word1 = each_pair[0]\n",
    "        word2 = each_pair[1]\n",
    "        if word1 < word2: ## welches wort länger ist\n",
    "            similarity_matrix[word1].append(word2)                  #defaultdict(<class 'list'>, {'exclude': ['inscribe']})\n",
    "            #print(similarity_matrix)\n",
    "        else:\n",
    "            similarity_matrix[word2].append(word1)\n",
    "\n",
    "    # computing similarity of antonyms:\n",
    "    all_similarity = defaultdict(dict)\n",
    "    for each_key in tqdm(similarity_matrix):\n",
    "        for each_value in similarity_matrix[each_key]:\n",
    "    #       cosine_similarity\n",
    "            all_similarity[each_key][each_value] = abs(cosine_similarity([current_model.wv[each_key]],[current_model.wv[each_value]])[0][0])\n",
    "\n",
    "    \n",
    "    final_antonym_list = []\n",
    "    for index_counter, each_key in enumerate(tqdm(all_similarity)):\n",
    "        listofTuples = sorted(all_similarity[each_key].items() ,  key=lambda x: x[1])\n",
    "        final_antonym_list.append((each_key, listofTuples[0][0]))\n",
    "\n",
    "    list_antonym = final_antonym_list\n",
    "    return list_antonym, all_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the ORTHOGONAL DIMENSION Order\n",
    "# Subspace selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLAR Framework code (https://github.com/Sandipan99/POLAR)\n",
    "\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cosine as scipy_cosine\n",
    "random.seed(42)\n",
    "\n",
    "def computedimension_similarity_matrix(antonymy_vector):\n",
    "    t1 = np.array(antonymy_vector)\n",
    "    dimension_similarity_matrix = defaultdict(dict)\n",
    "    for index_1, each_dim1 in enumerate(tqdm(t1)):\n",
    "        for index_2, each_dim2 in enumerate(t1):\n",
    "            dimension_similarity_matrix[index_1][index_2] = abs(1-scipy_cosine(each_dim1, each_dim2))\n",
    "    return dimension_similarity_matrix\n",
    "        \n",
    "def get_set_score(final_list, each_dim,antonymy_vector,similaityMatrix):\n",
    "    final_output = 0.0\n",
    "    dimension_similarity_matrix=similaityMatrix\n",
    "    for each_vec in final_list:\n",
    "        final_output += dimension_similarity_matrix[each_vec][each_dim]\n",
    "    return final_output/(len(final_list))\n",
    "        \n",
    "def select_subset_dimension(dim_vector, num_dim):\n",
    "    working_list = np.array(dim_vector)\n",
    "    \n",
    "    working_position_index = [i for i in range(working_list.shape[0])]\n",
    "    final_position_index = []\n",
    "    similaityMatrix=computedimension_similarity_matrix(dim_vector)\n",
    "\n",
    "    print('working list is ready, shape', working_list.shape)\n",
    "    sel_dim = random.randrange(0, working_list.shape[0])\n",
    "\n",
    "    final_position_index.append(sel_dim)\n",
    "    \n",
    "    working_position_index.remove(sel_dim)\n",
    "\n",
    "    \n",
    "    for test_count in tqdm(range(num_dim-1)):\n",
    "        min_dim = None\n",
    "        min_score = 1000\n",
    "        for temp_index, each_dim in enumerate(working_position_index):\n",
    "#             print(each_dim)\n",
    "            temp_score = get_set_score(final_position_index, each_dim,dim_vector,similaityMatrix)\n",
    "            if temp_score< min_score:\n",
    "                min_score= temp_score\n",
    "                min_dim = each_dim\n",
    "        #print(test_count,min_dim)\n",
    "        final_position_index.append(min_dim)\n",
    "        working_position_index.remove(min_dim)\n",
    "#         print(working_list.shape, len(final_list))\n",
    "    return final_position_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform into Polar space function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLAR Framework code (https://github.com/Sandipan99/POLAR)\n",
    "def transform_to_antonym_space(current_model, output_file_path, binary, current_antonymy_vector_inverse):\n",
    "    embedding_size = orthogonal_antonymy_vector.shape[0] #current_antonymy_vector_inverse.shape[0]   ##CHANGE THIS ACCORDINGLY!!!\n",
    "    print('New model size is',len(current_model.wv.vocab), embedding_size)\n",
    "\n",
    "    temp_file = None\n",
    "    \n",
    "    if binary:\n",
    "        temp_file = open(output_file_path,'wb')\n",
    "        temp_file.write(str.encode(str(len(current_model.wv.vocab))+' '+str(embedding_size)+'\\n'))\n",
    "    else:\n",
    "        temp_file = open(output_file_path,'w')\n",
    "        temp_file.write(str(len(current_model.wv.vocab))+' '+str(embedding_size)+'\\n')\n",
    "\n",
    "    total_words = 0\n",
    "    for each_word in tqdm(current_model.wv.vocab):\n",
    "        total_words += 1\n",
    "        if binary:\n",
    "            temp_file.write(str.encode(each_word+' '))\n",
    "        else:\n",
    "            temp_file.write(each_word+' ')\n",
    "\n",
    "        new_vector = np.matmul(current_antonymy_vector_inverse,current_model[each_word])\n",
    "\n",
    "        new_vector = new_vector/linalg.norm(new_vector)\n",
    "\n",
    "        \n",
    "        \n",
    "        if binary:\n",
    "            temp_file.write(new_vector)\n",
    "            temp_file.write(str.encode('\\n'))\n",
    "        else:\n",
    "            temp_file.write(str(new_vector))\n",
    "            temp_file.write('\\n')\n",
    "\n",
    "\n",
    "    temp_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Normal transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLAR Framework code (https://github.com/Sandipan99/POLAR)\n",
    "def standard_normal_dist_model(model, new_filename):\n",
    "    embedding_matrix = []\n",
    "    embedding_vocab = []\n",
    "\n",
    "    temp_file = open(new_filename,'wb')\n",
    "    temp_file.write(str.encode(str(model.vectors.shape[0])+' '+str(model.vectors.shape[1])+'\\n'))\n",
    "    \n",
    "    for each_word in tqdm(model.wv.vocab):\n",
    "        embedding_matrix.append(model[each_word])\n",
    "        embedding_vocab.append(each_word)\n",
    "    \n",
    "    embedding_matrix = np.array(embedding_matrix)\n",
    "    \n",
    "    print('The shape of embedding matrix is {}'.format(embedding_matrix.shape))\n",
    "    \n",
    "    norm_embedding_matrix = (embedding_matrix - embedding_matrix.mean(0))/ embedding_matrix.std(0)\n",
    "    \n",
    "    for word_counter, each_word in enumerate(tqdm(embedding_vocab)):\n",
    "#         assert each_word==embedding_vocab[word_counter],'Not matching!!!'\n",
    "        \n",
    "        temp_file.write(str.encode(each_word+' '))\n",
    "        new_vector = norm_embedding_matrix[word_counter]\n",
    "        temp_file.write(new_vector)\n",
    "        temp_file.write(str.encode('\\n'))\n",
    "        \n",
    "    del embedding_matrix\n",
    "    del embedding_vocab\n",
    "    temp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulizing polar dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function plots the value of a word on a polar dimension in 2d\n",
    "def plotPolar(left, right, value):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.set_figheight(1)\n",
    "    \n",
    "    if abs(value)>10:\n",
    "        fig.set_figwidth(20)\n",
    "        ar = np.arange(-20,21)   \n",
    "    else:\n",
    "        fig.set_figwidth(10)\n",
    "        ar = np.arange(-10,11)\n",
    "    ax1.plot(ar, np.zeros_like(ar) + 0, '.')\n",
    "    ax1.plot(value, 0, 'd', linewidth=2, markersize=20, color='r')\n",
    "    ax1.set_ylabel(left, color='b',rotation=0, size=20, labelpad=50)\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xticks(ar)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(right, color='r',rotation=0, size=20, labelpad=50)\n",
    "    ax2.set_yticks([])\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    ax2.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function Plots the value for the top 'numberPolar' dimensions of a word\n",
    "import matplotlib.pyplot as pp\n",
    "def getMeaningOfWord(strWord,antonymy_vector, model, numberPolar ):\n",
    "    #print(antonymy_vector)\n",
    "    word=model[strWord]\n",
    "    thisdict = {}\n",
    "    for count, value in enumerate(word):\n",
    "        thisdict[count]= value\n",
    "    sortedDic=sorted(thisdict.items(), key=lambda item: abs(item[1]))\n",
    "    sortedDic.reverse()\n",
    "   \n",
    "    for i in range(0,numberPolar):\n",
    "        cur_Index=sortedDic[i][0]\n",
    "        originalAntonymIndex=antonymy_vector[cur_Index]\n",
    "        print(sortedDic[i][1])\n",
    "        if cur_Index<50:\n",
    "            print(\"Original\")\n",
    "        else:\n",
    "            print(\"Extended\")\n",
    "        cur_value =sortedDic[i][1]\n",
    "        leftPolar=list_antonym[originalAntonymIndex][0]\n",
    "        rightPolar=list_antonym[originalAntonymIndex][1]\n",
    "        plotPolar(rightPolar, leftPolar, cur_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use wordnet to generate more antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    " \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet \n",
    "def addAntonyms(list_antonym, n):  \n",
    "    porter = PorterStemmer()\n",
    "    #Add n synonyms of the already existing pairs to the list\n",
    "    potentialPair=[]\n",
    "    for curAnto in list(sum(list_antonym, ())): #flatten the list of tuples\n",
    "        counter=0# only add maximal n synonyms\n",
    "        for syn in wordnet.synsets(curAnto): #access wordnet \n",
    "            for l in syn.lemmas(): \n",
    "                curName=l.name()\n",
    "                if counter>n-1:\n",
    "                    break       \n",
    "                if curName!=str(curAnto) and curName not in potentialPair: #check if its not the same word/ same word stem porter.stem(l.name())\n",
    "                    if curName in word2vec.wv.vocab:\n",
    "                        potentialPair.append(curName)\n",
    "                        counter+=1   \n",
    "\n",
    "  \n",
    "    newAnto=[]\n",
    "    for leftPair in potentialPair:\n",
    "        for syn in wordnet.synsets(leftPair): \n",
    "            for l in syn.lemmas(): \n",
    "                if l.antonyms(): \n",
    "                    rightPair=l.antonyms()[0].name()\n",
    "                    curSet=(leftPair,rightPair)\n",
    "                    curSetStemmed=(leftPair,porter.stem(rightPair))\n",
    "                    if curSet not in newAnto and curSetStemmed not in curSetStemmed: #don't add already added pairs or their stemms\n",
    "                        if rightPair in word2vec.wv.vocab:\n",
    "                            newAnto.append(curSet)\n",
    "    print(\"The following antonym pairs have been added:\")\n",
    "    print(newAnto)\n",
    "    finalAnto=list_antonym\n",
    "    finalAnto.extend(newAnto)\n",
    "    return finalAnto\n",
    "#testlist_antonym=list_antonym.copy()\n",
    "#finalAnto=addAntonyms(testlist_antonym, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use https://www.synonyms.com/ to get more antonym pairs, can be slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def getAntonymsForWordSynonymsCom(word, model, n):\n",
    "    curWord=word\n",
    "    webSite=\"https://www.synonyms.com/antonyms/\"\n",
    "    response = requests.get(webSite+curWord)\n",
    "    #print(response)\n",
    "    antonyms=[]\n",
    "    counter=0\n",
    "    if response.status_code== 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        section = soup.findAll('p', {'class': 'ants'})#All\n",
    "        #print(section)\n",
    "        for sec in section:\n",
    "            for li in sec.findAll('a'):\n",
    "                if li.text in model.wv.vocab:   \n",
    "                    antonyms.append(li.text)\n",
    "                    counter+=1\n",
    "                    if counter==2:                       \n",
    "                        return antonyms\n",
    "    return antonyms    \n",
    "        \n",
    "#getAntonymsForWordSynonymsCom(\"dark\", word2vec, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generateNewPairs(model, originalPairs,n):\n",
    "    curVocab=list(sum(originalPairs, ())) #flatten the list of tupels \n",
    "    newPairs=originalPairs\n",
    "    for word in curVocab:\n",
    "        similarWords=model.most_similar(word)[0:5]\n",
    "        for simWord in similarWords:\n",
    "            wordText=simWord[0]\n",
    "            antonyms=getAntonymsForWordSynonymsCom(wordText, model, 2)\n",
    "            for ant in antonyms:\n",
    "                pair=(wordText,ant)\n",
    "                pair2=(ant,wordText) #\n",
    "                if pair not in newPairs and pair2 not in newPairs:\n",
    "                    newPairs.append(pair)\n",
    "                    \n",
    "    return newPairs\n",
    "#generateNewPairs(word2vec, list_antonym,2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSimilarWords(model, originalPairs):\n",
    "    curVocab=list(sum(originalPairs, ())) #flatten the list of tupels \n",
    "    newPairs=originalPairs\n",
    "    for word in curVocab:\n",
    "        similarWords=model.most_similar(word)[0:5]\n",
    "        for simWord in similarWords:\n",
    "            simWord=simWord[0]\n",
    "            for syn in wordnet.synsets(simWord): \n",
    "                for l in syn.lemmas():\n",
    "                    counter=0\n",
    "                    if l.antonyms(): \n",
    "                        rightPair=l.antonyms()[0].name()\n",
    "                        curSet=(simWord,rightPair)\n",
    "                        curSetBackwards=(rightPair,simWord)\n",
    "                        if curSet not in newPairs and curSetBackwards not in newPairs: #don't add already added pairs or their stemms\n",
    "                            if rightPair in word2vec.wv.vocab:\n",
    "                                newPairs.append(curSet)\n",
    "                                counter+=1\n",
    "                                if counter==5:\n",
    "                                    break\n",
    "    return newPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only run next cell if a new Wikipedia dataset is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if its your first time running this NodeBook\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0ad022a34748b1b0aae546cea1aed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='trainNewModel'), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "def myFunction(trainNewModel):\n",
    "    return trainNewModel\n",
    "print(\"Check if its your first time running this NodeBook\")\n",
    "trainNewModel=interact(myFunction, trainNewModel=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNewModel=False\n",
    "if trainNewModel==True:\n",
    "    wiki = WikiCorpus(r\"DataSets/enwiki-20200601-pages-articles-multistream1.xml-p1p30303.bz2\", \n",
    "                  lemmatize=False, dictionary={})\n",
    "    #store the preprocessed dataset, which reduces a lot of time later\n",
    "    wiki.save('SavedWord2Vec/wiki.corpus')\n",
    "    \n",
    "    sentences = list(wiki.get_texts()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size: The number of dimensions of the embeddings and the default is 100.\n",
    "\n",
    "window: The maximum distance between a target word and words around the target word. The default window is 5.\n",
    "\n",
    "min_count: The minimum count of words to consider when training the model; words with occurrence less than this \n",
    "count will be ignored. The default for min_count is 5.\n",
    "\n",
    "workers: The number of partitions during training and the default workers is 3.\n",
    "\n",
    "sg: The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model from file...\n",
      "Finished Loading\n"
     ]
    }
   ],
   "source": [
    "### Compute the Word2Vec model usint following parameters#\n",
    "if trainNewModel==True:\n",
    "    print(\"Training Word2Vec model ...\")\n",
    "    params = {'size': 300, 'window': 5, 'min_count': 5, \n",
    "          'workers': max(1, multiprocessing.cpu_count() - 1), 'sample': 1E-3,'sg' : 1}\n",
    "    word2vec = Word2Vec(sentences, **params)\n",
    "    ### Save Word2Vec model to file ###\n",
    "    word2vec.save('SavedWord2Vec/wiki.word2vec.model')\n",
    "    print(\"Finished Training\")\n",
    "else:\n",
    "    ### Loading finished Word2Vec model to memory from file ###\n",
    "    print(\"Loading Word2Vec model from file...\")\n",
    "    word2vec = Word2Vec.load('SavedWord2Vec/wiki.word2vec.model')\n",
    "    print(\"Finished Loading\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## King- Man + Woman = Queen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiliarity of king and queen: 0.62048626\n",
      "Smiliarity of transformed king and queen: 0.59351194\n",
      "The most similar words to out transformation of King to Queen are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.7447922229766846),\n",
       " ('queen', 0.5935120582580566),\n",
       " ('regnant', 0.5319673418998718),\n",
       " ('woman', 0.5265816450119019),\n",
       " ('consort', 0.5225052237510681),\n",
       " ('berengaria', 0.5126684308052063),\n",
       " ('urraca', 0.5116742253303528),\n",
       " ('kings', 0.5031053423881531),\n",
       " ('isabeau', 0.5030635595321655),\n",
       " ('monarch', 0.4930773079395294)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar words to out transformation of France to Japan are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tokyo', 0.7923076152801514),\n",
       " ('japan', 0.7168467044830322),\n",
       " ('osaka', 0.5796914100646973),\n",
       " ('kyushu', 0.5486371517181396),\n",
       " ('ehime', 0.5427321195602417),\n",
       " ('fukuoka', 0.5382509231567383),\n",
       " ('miyagi', 0.5322080850601196),\n",
       " ('ōita', 0.5318936705589294),\n",
       " ('chiba', 0.5310077667236328),\n",
       " ('hachiōji', 0.5294787287712097)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def similarityNameVector(vec, name, model):\n",
    "    cosineSimilarity = np.dot(vec, model.wv[name])/(np.linalg.norm(vec)* np.linalg.norm(model.wv[name]))\n",
    "    return cosineSimilarity\n",
    "\n",
    "print(\"Smiliarity of king and queen:\", word2vec.wv.similarity('king', 'queen'))\n",
    "ourQueen= word2vec.wv['king'] - word2vec.wv['man'] + word2vec.wv['woman']\n",
    "print(\"Smiliarity of transformed king and queen:\", similarityNameVector(ourQueen,'queen',word2vec))\n",
    "\n",
    "print(\"The most similar words to out transformation of King to Queen are:\")\n",
    "display(word2vec.wv.most_similar(positive=[ourQueen], topn=10)) # cosine similarity\n",
    "#word2vec.wv.most_similar(positive=[\"king\"], topn=10)\n",
    "\n",
    "ourJapan= word2vec.wv['france'] - word2vec.wv['paris'] + word2vec.wv['tokyo']\n",
    "print(\"The most similar words to out transformation of France to Japan are:\")\n",
    "display(word2vec.wv.most_similar(positive=[ourJapan], topn=10)) # cosine similarity\n",
    "#word2vec.wv.most_similar(positive=[\"king\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Antonyms and then Transformation to polar space\n",
    "## Parts were taken from the POLAR Framework code (https://github.com/Sandipan99/POLAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the task score for different dimension size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## POLAR Framework code (https://github.com/Sandipan99/POLAR) :\n",
    "def generate_embedding_path(current_model, embedding_path, binary, antonym_vector, curr_dim):\n",
    "    curr_antonym_vector = antonymy_vector[antonym_vector[:curr_dim]]\n",
    "    curr_antonymy_vector_inverse = np.linalg.pinv(np.transpose(curr_antonym_vector))\n",
    "    #transform to polar space and write3s to file\n",
    "    transform_to_antonym_space(current_model, embedding_path, binary,curr_antonymy_vector_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "[('silent', 'loud'), ('black', 'white'), ('woman', 'man'), ('recorded', 'live'), ('night', 'day'), ('king', 'queen'), ('young', 'old'), ('artificial', 'natural'), ('forte', 'piano'), ('international', 'domestic'), ('classic', 'modern'), ('medieval', 'future'), ('pop', 'classical'), ('monophonic', 'polyphonic'), ('vocal', 'instrumental'), ('harmony', 'dissonance'), ('fast', 'slow'), ('bass', 'high'), ('deep', 'high'), ('major', 'minor'), ('loud', 'piano'), ('western', 'eastern'), ('light', 'dark'), ('structure', 'unstructured'), ('rich', 'poor'), ('country', 'cultured'), ('progressive', 'regressive'), ('hip', 'uninformed'), ('dance', 'stand'), ('ambient', 'distant'), ('soul', 'body'), ('heavy', 'light'), ('electric', 'relaxed'), ('punk', 'superior'), ('loud', 'soft'), ('brassy', 'tasteful'), ('natural', 'electronic'), ('strong', 'weak'), ('deep', 'shallow'), ('full', 'empty'), ('piercing', 'dull'), ('harsh', 'pleasant'), ('resonant', 'flat'), ('pianissimo', 'fortissimo'), ('piano', 'forte'), ('energetic', 'gentle'), ('joyful', 'depressing'), ('shrill', 'pleading'), ('shrill', 'colourless'), ('deafening', 'soft'), ('white', 'blackness'), ('red', 'neutral'), ('red', 'uncolored'), ('yellow', 'new'), ('yellow', 'honourable'), ('black', 'whiteness'), ('blue', 'cheerful'), ('blue', 'clean'), ('girl', 'boy'), ('girl', 'son'), ('women', 'men'), ('voluptuous', 'strict'), ('person', 'generic'), ('person', 'common'), ('record', 'delete'), ('record', 'erase'), ('living', 'dead'), ('living', 'relative'), ('roam', 'hurry'), ('roam', 'speed'), ('morning', 'evening'), ('regnant', 'powerless'), ('preteen', 'old'), ('teenaged', 'old'), ('younger', 'senior'), ('younger', 'elder'), ('infirm', 'resolute'), ('infirm', 'robust'), ('balding', 'haired'), ('balding', 'hairy'), ('older', 'immature'), ('older', 'young'), ('artificially', 'naturally'), ('crude', 'skilled'), ('crude', 'late'), ('contemporary', 'asynchronous'), ('medieval', 'modern'), ('recognizably', 'unrecognisable'), ('mediaeval', 'modern'), ('ancient', 'young'), ('ancient', 'immature'), ('past', 'hereafter'), ('past', 'futurity'), ('foreseeable', 'unpredictable'), ('foretell', 'assure'), ('foretell', 'calculate'), ('present', 'awol'), ('present', 'absent'), ('sophistic', 'valid'), ('nonclassical', 'neoclassical'), ('nonclassical', 'classic'), ('polyphonic', 'monodic'), ('monophony', 'polyphony'), ('polyphony', 'monody'), ('monophonic', 'binaural'), ('monophonic', 'contrapuntal'), ('staccato', 'smooth'), ('staccato', 'legato'), ('falsetto', 'low'), ('tonality', 'atonality'), ('harmonious', 'dissonant'), ('harmonious', 'false'), ('consonance', 'discordance'), ('consonance', 'dissonance'), ('atonality', 'key'), ('slow', 'rapid'), ('slow', 'presto'), ('sluggish', 'active'), ('sluggish', 'fast'), ('fast', 'rough'), ('fast', 'moral'), ('low', 'high'), ('low', 'overlooking'), ('higher', 'low'), ('lower', 'lift'), ('lower', 'elevate'), ('shallow', 'sound'), ('shallow', 'unfathomable'), ('significant', 'inconsiderable'), ('significant', 'trivial'), ('minor', 'limitless'), ('main', 'unimportant'), ('main', 'mild'), ('principal', 'unimportant'), ('major', 'peanut'), ('eastern', 'occidental'), ('eastern', 'southwestern'), ('southern', 'northern'), ('southern', 'blue'), ('northern', 'gray'), ('northern', 'south'), ('west', 'eastern'), ('west', 'east'), ('southwestern', 'north'), ('western', 'northeastern'), ('east', 'westward'), ('east', 'westbound'), ('gleaming', 'dull'), ('bluish', 'achromatic'), ('bluish', 'neutral'), ('pale', 'colorful'), ('pale', 'colourful'), ('purplish', 'neutral'), ('purplish', 'achromatic'), ('reddish', 'neutral'), ('reddish', 'achromatic'), ('unpolluted', 'impure'), ('unpolluted', 'adulterated'), ('abundant', 'rare'), ('abundant', 'tight'), ('inadequate', 'equal'), ('inadequate', 'competent'), ('good', 'bad'), ('good', 'evil'), ('uneducated', 'lettered'), ('uneducated', 'literate'), ('substandard', 'standard'), ('centrist', 'right'), ('centrist', 'left'), ('conservative', 'liberal'), ('conservative', 'progressive'), ('deflationary', 'inflationary'), ('unsystematic', 'systematic'), ('untruthful', 'honest'), ('untruthful', 'truthful'), ('unproved', 'proved'), ('unproved', 'tried'), ('standing', 'temporary'), ('standing', 'sitting'), ('sit', 'stand'), ('sit', 'lie'), ('fusiform', 'pointless'), ('metal', 'nonmetal'), ('loosened', 'tangled'), ('loosening', 'tightening'), ('discouraging', 'hortatory'), ('discouraging', 'persuasive'), ('hardcore', 'disloyal'), ('hardcore', 'implicit'), ('thrash', 'fail'), ('thrash', 'fall'), ('inferior', 'superior'), ('inferior', 'superordinate'), ('hard', 'palatalised'), ('hard', 'diffused'), ('chewy', 'tender'), ('chewy', 'inelastic'), ('snappy', 'hot'), ('snappy', 'lethargic'), ('streetwise', 'stupid'), ('unoriginal', 'groundbreaking'), ('unoriginal', 'germinal'), ('clichéd', 'original'), ('unsentimental', 'tender'), ('limpid', 'unclear'), ('limpid', 'opaque'), ('weak', 'powerful'), ('weak', 'imperceptible'), ('stronger', 'weaker'), ('strong', 'puny'), ('strong', 'pallid'), ('weakly', 'robust'), ('weakly', 'strongly'), ('fledged', 'immature'), ('complete', 'imperfect'), ('complete', 'incomplete'), ('pretentious', 'unpretentious'), ('pretentious', 'modest'), ('disheveled', 'tidy'), ('disagreeable', 'congenial'), ('disagreeable', 'agreeable'), ('wiry', 'hairless'), ('wiry', 'fat'), ('harshness', 'courtesy'), ('harshness', 'gentleness'), ('brutal', 'mild'), ('brutal', 'humane'), ('atrocious', 'good'), ('pleasantly', 'unpleasantly'), ('windy', 'slow'), ('windy', 'concise'), ('refreshing', 'old'), ('refreshing', 'debilitating'), ('foggy', 'clear'), ('foggy', 'distinct'), ('featureless', 'fancy'), ('sloping', 'steep'), ('sloping', 'horizontal'), ('sloped', 'perpendicular'), ('sloped', 'vertical'), ('bottomed', 'bottomless'), ('fortissimo', 'soft'), ('fortissimo', 'piano'), ('pianissimo', 'forte'), ('pianissimo', 'loud'), ('courteous', 'impolite'), ('courteous', 'abrupt'), ('amiable', 'unfriendly'), ('affable', 'unfriendly'), ('affable', 'adverse'), ('joyous', 'joyless'), ('joyous', 'funereal'), ('somber', 'colorful'), ('somber', 'cheerful'), ('anguished', 'joyful'), ('claustrophobic', 'fearless'), ('depressed', 'high'), ('depressed', 'elated')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0e9471988c4324838cc0548ecd0b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=258.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9c1ee7b6b2477b8ce7a0487f72b4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d2234ad1064c65a3f04d5537f7dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Put it all together\n",
    "\n",
    "loadMusicAntonyms=True\n",
    "loadCountryAntonyms=False\n",
    "loadStandardAntonyms=False\n",
    "loadFoodAntonyms=False\n",
    "current_model=word2vec\n",
    "\n",
    "list_antonym=loadAntonyms(model=word2vec,loadMusicAntonyms=loadMusicAntonyms, loadCountryAntonyms=loadCountryAntonyms,loadStandardAntonyms=loadStandardAntonyms,loadFoodAntonyms=loadFoodAntonyms)\n",
    "print(len(list_antonym))\n",
    "\n",
    "## Use wordnet to generate more antonyms\n",
    "#list_antonym=addAntonyms(list_antonym, 2)  \n",
    "\n",
    "#add antonyms with synonyms.com and similarity\n",
    "list_antonym=generateNewPairs(word2vec, list_antonym,2) \n",
    "\n",
    "# add antonyms with wordnet and similarity\n",
    "#list_antonym=addSimilarWords(word2vec, list_antonym)\n",
    "\n",
    "# add antonyms from scratch (corpus needed see bottom of this ipynb)\n",
    "#list_antonym=creatAntonymsFromCategory(genreCorpus,word2vec)\n",
    "\n",
    "list_antonym, all_similarity=computeFinalAntonymsSimilariy(list_antonym)\n",
    "\n",
    "nameTag=\"MusicExtended\" #Standard #Food #Country #CountryExtended #Genre\n",
    "\n",
    "\n",
    "with open(\"SavedWord2Vec/AntonymVector\"+nameTag+\".txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(list_antonym, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Find the antonym difference vectors\n",
    "antonymy_vector = []\n",
    "for each_word_pair in list_antonym:\n",
    "    antonymy_vector.append(current_model.wv[each_word_pair[0]]- current_model.wv[each_word_pair[1]])\n",
    "antonymy_vector = np.array(antonymy_vector)\n",
    "print(antonymy_vector.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Get the orthogonal dimension order\n",
    "if len(list_antonym)>300:\n",
    "    num_antonym = 300#1468\n",
    "    orthogonal_antonymy_vector =np.array(select_subset_dimension(antonymy_vector, num_antonym))  \n",
    "else:\n",
    "    num_antonym=len(list_antonym)-1\n",
    "    orthogonal_antonymy_vector = np.array(range(num_antonym))\n",
    "\n",
    "\n",
    "\n",
    "antonym_vector_method = orthogonal_antonymy_vector # we used only the orthogonality method from the original paper\n",
    "with open(\"SavedWord2Vec/chosenAntonyms\"+nameTag+\".txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(antonym_vector_method, fp)\n",
    "\n",
    "curr_dim = len(antonym_vector_method)#dim_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model size is 147989 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa99cd5528f40ddad90f01997a297b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=147989.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading the model\n",
      "loading done..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a2894cd3e2499c9e3d2f15e9bf1519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=147989.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shape of embedding matrix is (147989, 208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c638eb83542c4282b943ef14cbba9636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=147989.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_path = r'SavedWord2Vec/polarEmbedding'+nameTag+str(curr_dim)\n",
    "#embedding_path = r'polarEmbeddingFood265'   \n",
    "# model is transformed to polar space and stored as a file\n",
    "generate_embedding_path(current_model, embedding_path+'.bin',True,antonym_vector_method, curr_dim)\n",
    "\n",
    "# Model is loaded from file to memory\n",
    "print('loading the model')\n",
    "temp_model = gensim.models.KeyedVectors.load_word2vec_format(embedding_path+'.bin', binary=True)\n",
    "print('loading done..')\n",
    "\n",
    "\n",
    "#Model is tranformed to standard normal and stored to file\n",
    "  \n",
    "std_nrml_embedding_path =embedding_path+'_StdNrml.bin'\n",
    "\n",
    "standard_normal_dist_model(temp_model, std_nrml_embedding_path)\n",
    "\n",
    "del temp_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Polar model into memory\n",
      "Finished Loading\n"
     ]
    }
   ],
   "source": [
    "curr_dim = num_antonym\n",
    "#embedding_path = r'SavedWord2Vec/polarEmbedding'+str(curr_dim)    \n",
    "nameTag=\"MusicExtended\"\n",
    "embedding_path = r'SavedWord2Vec/polarEmbedding'+nameTag+str(curr_dim)\n",
    "path=embedding_path+'_StdNrml.bin'\n",
    "# Load the normalized model in Polar dimensions into memory\n",
    "print(\"Load Polar model into memory\")\n",
    "word2vecPolar = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "print(\"Finished Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"SavedWord2Vec/AntonymVector\"+nameTag+\".txt\", \"rb\") as fp:   # Unpickling\n",
    "    list_antonym = pickle.load(fp)\n",
    "with open(\"SavedWord2Vec/chosenAntonyms\"+nameTag+\".txt\", \"rb\") as fp:   # Unpickling\n",
    "    orthogonal_antonymy_vector = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 30 polar dimensions for a word\n",
    "currWord='beethoven'\n",
    "howManyDimension=30\n",
    "\n",
    "getMeaningOfWord(currWord,orthogonal_antonymy_vector, word2vecPolar, howManyDimension )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Antonyms from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def creatAntonymsFromCategory(document,current_model):  \n",
    "    porter = PorterStemmer()\n",
    "    #Add n synonyms of the already existing pairs to the list\n",
    "    \n",
    "    antonyms=[]\n",
    "    for word in document.split(\" \"):\n",
    "        for syn in wordnet.synsets(word): #access wordnet \n",
    "                typePos=syn.name()[1]\n",
    "                for l in syn.lemmas(): \n",
    "                    #print(l.name())   \n",
    "                    if l.antonyms():\n",
    "                        pair=(l.name(),l.antonyms()[0].name())\n",
    "                        if pair not in antonyms and pair[0] in current_model.wv.vocab and pair[1] in current_model.wv.vocab:\n",
    "                            antonyms.append(pair)\n",
    "    return antonyms\n",
    "\n",
    "#creatAntonymsFromCategory(testChina,word2vecPolar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old test code, not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUSA=\"The United States of America (USA), commonly known as the United States (U.S. or US) or America, is a country mostly located in central North America, between Canada and Mexico. It consists of 50 states, a federal district, five major self-governing territories, and various possessions.[h] At 3.8 million square miles (9.8 million km2), it is the world's third- or fourth-largest country by total area.[d] With a 2019 estimated population of over 328 million,[7] the U.S. is the third most populous country in the world. The capital is Washington, D.C., and the most populous city is New York City. Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago,[19] and European colonization began in the 16th century. The United States emerged from the thirteen British colonies established along the East Coast. Numerous disputes between Great Britain and the colonies led to the American Revolutionary War lasting between 1775 and 1783, leading to independence.[20] Beginning in the late 18th century, the United States vigorously expanded across North America, gradually acquiring new territories,[21] killing and displacing Native Americans, and admitting new states. By 1848, the United States spanned the continent.[21] Slavery was legal in much of the United States from the 17th to the second half of the 19th century, when the American Civil War led to its abolition.[22][23]The Spanish–American War and World War I entrenched the U.S. as a world power, a status confirmed by the outcome of World War II. It was the first country to develop nuclear weapons and is the only country to have used them in warfare. During the Cold War, the United States and the Soviet Union competed in the Space Race, culminating with the 1969 Apollo 11 mission, the spaceflight that first landed humans on the Moon. The end of the Cold War and collapse of the Soviet Union in 1991 left the United States as the world's sole superpower.[24]The United States is a federal republic and a representative democracy. It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States (OAS), NATO, and other international organizations. It is a permanent member of the United Nations Security Council.A highly developed country, the United States is the world's largest economy and accounts for approximately a quarter of global gross domestic product (GDP).[25] The United States is the world's largest importer and the second-largest exporter of goods, by value.[26][27] Although its population is only 4.3% of the world total,[28] it holds 29.4% of the total wealth in the world, the largest share held by any country.[29] Despite income and wealth disparities, the United States continues to rank very high in measures of socioeconomic performance, including average wage, median income, median wealth, human development, per capita GDP, and worker productivity.[30][31] It is the foremost military power in the world, making up more than a third of global military spending,[32] and is a leading political, cultural, and scientific force internationally.[33]\"\n",
    "testRussia=\"Russia (Russian: Росси́я, tr. Rossiya, IPA: [rɐˈsʲijə]), or the Russian Federation,[13][d] is a transcontinental country located in Eastern Europe and Northern Asia.[14] Covering an area of 17,125,200 square kilometres (6,612,100 sq mi),[15] it is the largest country in the world by area, spanning more than one-eighth of the Earth's inhabited land area,[16][17] stretching eleven time zones, and bordering 16 sovereign nations. The territory of Russia extends from the Baltic Sea in the west to the Pacific Ocean in the east, and from the Arctic Ocean in the north to the Black Sea and the Caucasus in the south. With 146.7 million inhabitants living in the country's 85 federal subjects,[8] Russia is the most populous nation in Europe and the ninth-most populous nation in the world.[18][19] Russia's capital and largest city is Moscow; other major urban areas include Saint Petersburg, Novosibirsk, Yekaterinburg, Nizhny Novgorod, Kazan and Chelyabinsk. The East Slavs emerged as a recognisable group in Europe between the 3rd and 8th centuries AD.[20] The medieval state of Rus' arose in the 9th century. In 988 it adopted Orthodox Christianity from the Byzantine Empire, beginning the synthesis of Byzantine and Slavic cultures that defined Russian culture for the next millennium.[21] Rus' ultimately disintegrated into a number of smaller states,[22] until it was finally reunified by the Grand Duchy of Moscow in the 15th century. By the 18th century, the nation had greatly expanded through conquest, annexation, and exploration to become the Russian Empire, which was the third largest empire in history, stretching from Norway on the west to Alaska on the east.[23][24] Following the Russian Revolution, the Russian Soviet Federative Socialist Republic (Russian SFSR) became the largest and leading constituent of the Union of Soviet Socialist Republics (USSR/Soviet Union), the world's first constitutionally socialist state.[25] The Soviet Union played a decisive role in the Allied victory in World War II,[26][27] and emerged as a recognised superpower and rival to the United States during the Cold War. The Soviet era saw some of the most significant technological achievements of the 20th century, including the world's first human-made satellite and the launching of the first humans in space. Following the dissolution of the Soviet Union in 1991, the Russian SFSR reconstituted itself as the Russian Federation and is recognised as the continuing legal personality and a successor of the USSR.[28] Since 1993, Russia is governed as a federal semi-presidential republic.[3] Vladimir Putin has dominated Russia's political system since 2000, serving as either president or prime minister.[29] His government has been accused by non-governmental organisations of numerous human rights abuses, authoritarianism and corruption. In response, Putin has argued that Western-style liberalism is obsolete in Russia, while maintaining that the country is still a democratic nation.[30][31][32] The Russian economy ranks as the fifth-largest in Europe, the eleventh-largest in the world by nominal GDP and the fifth-largest by PPP.[33] Russia's extensive mineral and energy resources are the largest such reserves in the world,[34] making it one of the leading producers of oil and natural gas globally.[35][36] The country is one of the five recognised nuclear weapons states and possesses the largest stockpile of nuclear warheads.[37] Russia is a major great power, as well as a regional power, and has been characterised as a potential superpower. The Russian Armed Forces have been ranked as the world's second most powerful, and the most powerful in Europe. Russia hosts the world's ninth-greatest number of UNESCO World Heritage Sites, at 29,[38] and is among the world's most popular tourist destinations.[39] It is a permanent member of the United Nations Security Council and an active global partner of ASEAN,[40][41][42] as well as a member of the Shanghai Cooperation Organisation (SCO), the G20, the Council of Europe, the Asia-Pacific Economic Cooperation (APEC), the Organization for Security and Co-operation in Europe (OSCE), the International Investment Bank (IIB) and the World Trade Organization (WTO), as well as being the leading member of the Commonwealth of Independent States (CIS), the Collective Security Treaty Organization (CSTO) and a member of the Eurasian Economic Union (EAEU).Russia (Russian: Росси́я, tr. Rossiya, IPA: [rɐˈsʲijə]), or the Russian Federation,[13][d] is a transcontinental country located in Eastern Europe and Northern Asia.[14] Covering an area of 17,125,200 square kilometres (6,612,100 sq mi),[15] it is the largest country in the world by area, spanning more than one-eighth of the Earth's inhabited land area,[16][17] stretching eleven time zones, and bordering 16 sovereign nations. The territory of Russia extends from the Baltic Sea in the west to the Pacific Ocean in the east, and from the Arctic Ocean in the north to the Black Sea and the Caucasus in the south. With 146.7 million inhabitants living in the country's 85 federal subjects,[8] Russia is the most populous nation in Europe and the ninth-most populous nation in the world.[18][19] Russia's capital and largest city is Moscow; other major urban areas include Saint Petersburg, Novosibirsk, Yekaterinburg, Nizhny Novgorod, Kazan and Chelyabinsk. The East Slavs emerged as a recognisable group in Europe between the 3rd and 8th centuries AD.[20] The medieval state of Rus' arose in the 9th century. In 988 it adopted Orthodox Christianity from the Byzantine Empire, beginning the synthesis of Byzantine and Slavic cultures that defined Russian culture for the next millennium.[21] Rus' ultimately disintegrated into a number of smaller states,[22] until it was finally reunified by the Grand Duchy of Moscow in the 15th century. By the 18th century, the nation had greatly expanded through conquest, annexation, and exploration to become the Russian Empire, which was the third largest empire in history, stretching from Norway on the west to Alaska on the east.[23][24] Following the Russian Revolution, the Russian Soviet Federative Socialist Republic (Russian SFSR) became the largest and leading constituent of the Union of Soviet Socialist Republics (USSR/Soviet Union), the world's first constitutionally socialist state.[25] The Soviet Union played a decisive role in the Allied victory in World War II,[26][27] and emerged as a recognised superpower and rival to the United States during the Cold War. The Soviet era saw some of the most significant technological achievements of the 20th century, including the world's first human-made satellite and the launching of the first humans in space. Following the dissolution of the Soviet Union in 1991, the Russian SFSR reconstituted itself as the Russian Federation and is recognised as the continuing legal personality and a successor of the USSR.[28] Since 1993, Russia is governed as a federal semi-presidential republic.[3] Vladimir Putin has dominated Russia's political system since 2000, serving as either president or prime minister.[29] His government has been accused by non-governmental organisations of numerous human rights abuses, authoritarianism and corruption. In response, Putin has argued that Western-style liberalism is obsolete in Russia, while maintaining that the country is still a democratic nation.[30][31][32]The Russian economy ranks as the fifth-largest in Europe, the eleventh-largest in the world by nominal GDP and the fifth-largest by PPP.[33] Russia's extensive mineral and energy resources are the largest such reserves in the world,[34] making it one of the leading producers of oil and natural gas globally.[35][36] The country is one of the five recognised nuclear weapons states and possesses the largest stockpile of nuclear warheads.[37] Russia is a major great power, as well as a regional power, and has been characterised as a potential superpower. The Russian Armed Forces have been ranked as the world's second most powerful, and the most powerful in Europe. Russia hosts the world's ninth-greatest number of UNESCO World Heritage Sites, at 29,[38] and is among the world's most popular tourist destinations.[39] It is a permanent member of the United Nations Security Council and an active global partner of ASEAN,[40][41][42] as well as a member of the Shanghai Cooperation Organisation (SCO), the G20, the Council of Europe, the Asia-Pacific Economic Cooperation (APEC), the Organization for Security and Co-operation in Europe (OSCE), the International Investment Bank (IIB) and the World Trade Organization (WTO), as well as being the leading member of the Commonwealth of Independent States (CIS), the Collective Security Treaty Organization (CSTO) and a member of the Eurasian Economic Union (EAEU).\"\n",
    "testBrazil=\"Brazil (Portuguese: Brasil; Brazilian Portuguese: [bɾaˈziw]),[nt 1] officially the Federative Republic of Brazil (Portuguese: About this soundRepública Federativa do Brasil),[10] is the largest country in both South America and Latin America. At 8.5 million square kilometers (3.2 million square miles)[11] and with over 211 million people, Brazil is the world's fifth-largest country by area and the sixth most populous. Its capital is Brasília, and its most populous city is São Paulo. The federation is composed of the union of the 26 states and the Federal District. It is the largest country to have Portuguese as an official language and the only one in the Americas;[12][13] it is also one of the most multicultural and ethnically diverse nations, due to over a century of mass immigration from around the world.[14] Bounded by the Atlantic Ocean on the east, Brazil has a coastline of 7,491 kilometers (4,655 mi).[15] It borders all other countries in South America except Ecuador and Chile and covers 47.3% of the continent's land area.[16] Its Amazon River basin includes a vast tropical forest, home to diverse wildlife, a variety of ecological systems, and extensive natural resources spanning numerous protected habitats.[15] This unique environmental heritage makes Brazil one of 17 megadiverse countries, and is the subject of significant global interest and debate regarding deforestation and environmental protection. Brazil was inhabited by numerous tribal nations prior to the landing in 1500 of explorer Pedro Álvares Cabral, who claimed the area for the Portuguese Empire. Brazil remained a Portuguese colony until 1808, when the capital of the empire was transferred from Lisbon to Rio de Janeiro. In 1815, the colony was elevated to the rank of kingdom upon the formation of the United Kingdom of Portugal, Brazil and the Algarves. Independence was achieved in 1822 with the creation of the Empire of Brazil, a unitary state governed under a constitutional monarchy and a parliamentary system. The ratification of the first constitution in 1824 led to the formation of a bicameral legislature, now called the National Congress. The country became a presidential republic in 1889 following a military coup d'état. An authoritarian military junta came to power in 1964 and ruled until 1985, after which civilian governance resumed. Brazil's current constitution, formulated in 1988, defines it as a democratic federal republic.[17] Due to its rich culture and history, the country ranks thirteenth in the world by number of UNESCO World Heritage Sites.[18] Brazil is classified as an upper-middle income economy by the World Bank[19] and a developing country,[20] with the largest share of global wealth in Latin America. It is considered an advanced emerging economy.[21] It has the ninth largest GDP in the world by nominal, and eight by PPP measures.[22][23] It is one of the world's major breadbaskets, being the largest producer of coffee for the last 150 years.[24] Brazil is a regional power and sometimes considered a great[25][26][27] or a middle power in international affairs.[27][28][29][30][31][26] On account of its international recognition and influence, the country is subsequently classified as an emerging power[32] and a potential superpower by several analysts.[33][34][35] Brazil is a founding member of the United Nations, the G20, BRICS, Union of South American Nations, Mercosul, Organization of American States, Organization of Ibero-American States and the Community of Portuguese Language Countries.\"\n",
    "testIndia=\"India, officially the Republic of India (Hindi: Bhārat Gaṇarājya),[23] is a country in South Asia. It is the second-most populous country, the seventh-largest country by area, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia. Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest, unfolding as the language of the Rigveda, and recording the dawning of Hinduism in India.[27] The Dravidian languages of India were supplanted in the northern regions.[28] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[29] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[30] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[31] Their collective era was suffused with wide-ranging creativity,[32] but also marked by the declining status of women,[33] and the incorporation of untouchability into an organised system of belief.[g][34] In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia.[35] In the early medieval era, Christianity, Islam, Judaism, and Zoroastrianism put down roots on India's southern and western coasts.[36] Muslim armies from Central Asia intermittently overran India's northern plains,[37] eventually establishing the Delhi Sultanate, and drawing northern India into the cosmopolitan networks of medieval Islam.[38] In the 15th century, the Vijayanagara Empire created a long-lasting composite Hindu culture in south India.[39] In the Punjab, Sikhism emerged, rejecting institutionalised religion.[40] The Mughal Empire, in 1526, ushered in two centuries of relative peace,[41] leaving a legacy of luminous architecture.[h][42] Gradually expanding rule of the British East India Company followed, turning India into a colonial economy, but also consolidating its sovereignty.[43] British Crown rule began in 1858. The rights promised to Indians were granted slowly,[44] but technological changes were introduced, and ideas of education, modernity and the public life took root.[45] A pioneering and influential nationalist movement emerged,[46] which was noted for nonviolent resistance and led India to its independence in 1947. India is a secular federal republic governed in a democratic parliamentary system. It is a pluralistic, multilingual and multi-ethnic society. India's population grew from 361 million in 1951 to 1,211 million in 2011.[47] During the same time, its nominal per capita income increased from US$64 annually to US$1,498, and its literacy rate from 16.6% to 74%. From being a comparatively destitute country in 1951,[48] India has become a fast-growing major economy, a hub for information technology services, with an expanding middle class.[49] It has a space programme which includes several planned or completed extraterrestrial missions. Indian movies, music, and spiritual teachings play an increasing role in global culture.[50] India has substantially reduced its rate of poverty, though at the cost of increasing economic inequality.[51] India is a nuclear weapons state, which ranks high in military expenditure. It has disputes over Kashmir with its neighbours, Pakistan and China, unresolved since the mid-20th century.[52] Among the socio-economic challenges India faces are gender inequality, child malnutrition,[53] and rising levels of air pollution.[54] India's land is megadiverse, with four biodiversity hotspots.[55] Its forest cover comprises 21.4% of its area.[56] India's wildlife, which has traditionally been viewed with tolerance in India's culture,[57] is supported among these forests, and elsewhere, in protected habitats.\"\n",
    "testFrance=\"France (French: [fʁɑ̃s] (About this soundlisten)), officially the French Republic (French: République française, pronounced [ʁepyblik fʁɑ̃sɛːz] (About this soundlisten)), is a country whose territory consists of metropolitan France in Western Europe and several overseas regions and territories.[XIII] The metropolitan area of France extends from the Mediterranean Sea to the English Channel and the North Sea, and from the Rhine to the Atlantic Ocean. It is bordered by Belgium, Luxembourg and Germany to the northeast, Switzerland, Monaco, and Italy to the east, and Andorra and Spain to the south. The overseas territories include French Guiana in South America and several islands in the Atlantic, Pacific and Indian oceans. The country's 18 integral regions (five of which are situated overseas) span a combined area of 643,801 square kilometres (248,573 sq mi) and a total population of 67.07 million (as of May 2020).[10] France is a unitary semi-presidential republic with its capital in Paris, the country's largest city and main cultural and commercial centre. Other major urban areas include Lyon, Marseille, Toulouse, Bordeaux, Lille and Nice. France, including its overseas territories, has the most number of time zones of any country, with a total of 12. During the Iron Age, what is now metropolitan France was inhabited by the Gauls, a Celtic people. Rome annexed the area in 51 BC, holding it until the arrival of Germanic Franks in 476, who formed the Kingdom of Francia. The Treaty of Verdun of 843 partitioned Francia into East Francia, Middle Francia and West Francia. West Francia, which became the Kingdom of France in 987, emerged as a major European power in the Middle Ages under King Philip Augustus. During the Renaissance, French culture flourished and a global colonial empire was established, which by the 20th century would become the second largest in the world.[11] The 16th century was dominated by religious civil wars between Catholics and Protestants (Huguenots). France became Europe's dominant cultural, political, and military power in the 17th century under Louis XIV.[12] In the late 18th century, the French Revolution overthrew the absolute monarchy, establishing one of modern history's earliest republics and drafting the Declaration of the Rights of Man and of the Citizen, which expresses the nation's ideals to this day. In the 19th century, Napoleon took power and established the First French Empire. His subsequent Napoleonic Wars (1803–15) shaped the course of continental Europe. Following the collapse of the Empire, France endured a tumultuous succession of governments culminating with the establishment of the French Third Republic in 1870. France was a major participant in World War I, from which it emerged victorious, and was one of the Allies in World War II, but came under occupation by the Axis powers in 1940. Following liberation in 1944, a Fourth Republic was established and later dissolved in the course of the Algerian War. The Fifth Republic, led by Charles de Gaulle, was formed in 1958 and remains today. Algeria and nearly all the other colonies became independent in the 1960s, with most retaining close economic and military connections with France. France has long been a global centre of art, science, and philosophy. It hosts the world's fifth-largest number of UNESCO World Heritage Sites and is the leading tourist destination, receiving over 89 million foreign visitors in 2018.[13] France is a developed country with the world's seventh-largest economy by nominal GDP, and the tenth-largest by PPP. In terms of aggregate household wealth, it ranks fourth in the world.[14] France performs well in international rankings of education, health care, life expectancy, and human development.[15][16] France is considered a great power in global affairs,[17] being one of the five permanent members of the United Nations Security Council with the power to veto and an official nuclear-weapon state. It is a leading member state of the European Union and the Eurozone,[18] and a member of the Group of 7, North Atlantic Treaty Organization (NATO), Organisation for Economic Co-operation and Development (OECD), the World Trade Organization (WTO), and La Francophonie.\"\n",
    "testGermany=\"Germany (German: Deutschland, German pronunciation: [ˈdɔʏtʃlant]), officially the Federal Republic of Germany (German: Bundesrepublik Deutschland, About this soundlisten),[e] is a country in Central and Western Europe. Covering an area of 357,022 square kilometres (137,847 sq mi), it lies between the Baltic and North seas to the north, and the Alps to the south. It borders Denmark to the north, Poland and the Czech Republic to the east, Austria and Switzerland to the south, and France, Luxembourg, Belgium, and the Netherlands to the west. Various Germanic tribes have inhabited the northern parts of modern Germany since classical antiquity. A region named Germania was documented before AD 100. Beginning in the 10th century, German territories formed a central part of the Holy Roman Empire. During the 16th century, northern German regions became the centre of the Protestant Reformation. After the collapse of the Holy Roman Empire, the German Confederation was formed in 1815. In 1871, Germany became a nation state when most of the German states unified into the Prussian-dominated German Empire. After World War I and the German Revolution of 1918–1919, the Empire was replaced by the parliamentary Weimar Republic. The Nazi seizure of power in 1933 led to the establishment of a dictatorship, World War II, and the Holocaust. After the end of World War II in Europe and a period of Allied occupation, two new German states were founded: West Germany and East Germany. The Federal Republic of Germany was a founding member of the European Economic Community and the European Union. The country was reunified on 3 October 1990. Today, Germany is a federal parliamentary republic led by a chancellor. With 83 million inhabitants of its 16 constituent states, it is the second-most populous country in Europe after Russia, as well as the most populous member state of the European Union. Its capital and largest city is Berlin, and its financial centre is Frankfurt; the largest urban area is the Ruhr. Germany is a great power with a strong economy; it has the largest economy in Europe, the world's fourth-largest economy by nominal GDP, and the fifth-largest by PPP. As a global leader in several industrial and technological sectors, it is both the world's third-largest exporter and importer of goods. A highly developed country with a very high standard of living, it offers social security and a universal health care system, environmental protections, and a tuition-free university education. Germany is also a member of the United Nations, NATO, the G7, the G20, and the OECD. Known for its long and rich cultural history, Germany has many World Heritage sites and is among the top tourism destinations in the world.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDocument=testUSA+testRussia+testBrazil+testIndia+testFrance+testGermany\n",
    "countryAntonyms=creatAntonymsFromCategory(countryDocument,word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('east', 'west')\n",
      "('north', 'south')\n",
      "('large', 'small')\n",
      "('black', 'white')\n",
      "('developed', 'undeveloped')\n",
      "('poor', 'rich')\n",
      "('urban', 'rural')\n",
      "('democratic', 'undemocratic')\n",
      "('liberal', 'conservative')\n",
      "('capitalism', 'socialism')\n",
      "('king', 'queen')\n",
      "('left', 'right')\n",
      "('hot', 'cold')\n",
      "('export', 'import')\n",
      "('decentralize', 'centralize')\n",
      "('beautiful', 'ugly')\n",
      "('expensive', 'cheap')\n",
      "('big', 'small')\n",
      "('popular', 'unpopular')\n"
     ]
    }
   ],
   "source": [
    " # Check which hand-crafted pairs were also found this way\n",
    "    with open(r'Antonym_sets/country50.txt') as fp:\n",
    "            for line in fp:\n",
    "                parts = line.split()\n",
    "                if parts[1]!=' ':\n",
    "                    word1 = parts[0]\n",
    "                    word2 = parts[1]\n",
    "                    pair1=(word1,word2)\n",
    "                    pair2=(word2,word1)\n",
    "                    if pair1 in countryAntonyms or pair2 in countryAntonyms:\n",
    "                        print(pair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating corpus for different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "genreCorpus=\"\"\n",
    "musicGenres=[\"African_popular_music\",\"Music_of_China\",\"Blues\",\"Country_music\",\"Electronic_music\",\"Folk_music\",\"Hip_hop_music\",\"Jazz\",\"Music_of_Spain\",\"Pop_music\",\"Rhythm_and_blues\",\"Soul_music\",\"Rock_music\",\"Classical_music\"]\n",
    "for genre in musicGenres:\n",
    "    try:\n",
    "        p = wikipedia.page(title=genre)\n",
    "        print(p.url)\n",
    "        print(p.title)\n",
    "        content = p.content # Content of page.\n",
    "        genreCorpus+=str(p.content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Germany\n",
      "Germany\n",
      "https://en.wikipedia.org/wiki/United_States\n",
      "United States\n",
      "https://en.wikipedia.org/wiki/China\n",
      "China\n",
      "https://en.wikipedia.org/wiki/Japan\n",
      "Japan\n",
      "https://en.wikipedia.org/wiki/India\n",
      "India\n",
      "https://en.wikipedia.org/wiki/United_Kingdom\n",
      "United Kingdom\n",
      "https://en.wikipedia.org/wiki/France\n",
      "France\n",
      "https://en.wikipedia.org/wiki/Italy\n",
      "Italy\n",
      "https://en.wikipedia.org/wiki/Brazil\n",
      "Brazil\n",
      "https://en.wikipedia.org/wiki/Canada\n",
      "Canada\n",
      "https://en.wikipedia.org/wiki/Russia\n",
      "Russia\n"
     ]
    }
   ],
   "source": [
    "\n",
    "countryCorpus=\"\"\n",
    "\n",
    "countries=[\"germany\", \"United_States\",\"China\",\"Japan\",\"India\",\"United_Kingdom\",\"France\", \"Italy\", \"Brazil\", \"Canada\",\"Russia\"]\n",
    "for countryName in countries:\n",
    "    p = wikipedia.page(countryName)\n",
    "    print(p.url)\n",
    "    print(p.title)\n",
    "    content = p.content # Content of page.\n",
    "    countryCorpus+=str(p.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryAntonyms=creatAntonymsFromCategory(str(countryCorpus),word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Hot_dog\n",
      "Hot dog\n",
      "https://en.wikipedia.org/wiki/Ramen\n",
      "Ramen\n",
      "https://en.wikipedia.org/wiki/Salad\n",
      "Salad\n",
      "https://en.wikipedia.org/wiki/Banana\n",
      "Banana\n",
      "https://en.wikipedia.org/wiki/Apply\n",
      "Apply\n",
      "https://en.wikipedia.org/wiki/Ice\n",
      "Ice\n",
      "https://en.wikipedia.org/wiki/Coffee\n",
      "Coffee\n",
      "https://en.wikipedia.org/wiki/Sushi\n",
      "Sushi\n",
      "https://en.wikipedia.org/wiki/Brazil\n",
      "Brazil\n",
      "https://en.wikipedia.org/wiki/Park\n",
      "Park\n",
      "https://en.wikipedia.org/wiki/Steak\n",
      "Steak\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "foodCorpus=\"\"\n",
    "\n",
    "foods=[\"Hot_dog\", \"Ramen\",\"Salad\",\"Banana\",\"Apple\",\"Juice\",\"Coffee\", \"Sushi\", \"Brazil\", \"Pork\",\"Steak\"]\n",
    "for foodName in foods:\n",
    "    p = wikipedia.page(foodName)\n",
    "    print(p.url)\n",
    "    print(p.title)\n",
    "    content = p.content # Content of page.\n",
    "    foodCorpus+=str(p.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hot', 'cold'),\n",
       " ('equal', 'differ'),\n",
       " ('partly', 'wholly'),\n",
       " ('fire', 'hire'),\n",
       " ('used', 'misused'),\n",
       " ('just', 'unjust'),\n",
       " ('equitable', 'inequitable'),\n",
       " ('fair', 'unfair'),\n",
       " ('assemble', 'disassemble'),\n",
       " ('preparation', 'resolution'),\n",
       " ('deviate', 'conform'),\n",
       " ('typical', 'atypical'),\n",
       " ('include', 'exclude'),\n",
       " ('admit', 'exclude'),\n",
       " ('common', 'individual'),\n",
       " ('common', 'uncommon'),\n",
       " ('import', 'export'),\n",
       " ('popular', 'unpopular'),\n",
       " ('unite', 'divide'),\n",
       " ('united', 'divided'),\n",
       " ('sell', 'buy'),\n",
       " ('sold', 'unsold'),\n",
       " ('stand', 'sit'),\n",
       " ('stand', 'yield'),\n",
       " ('associate', 'dissociate'),\n",
       " ('connect', 'disconnect'),\n",
       " ('connected', 'unconnected'),\n",
       " ('new', 'old'),\n",
       " ('new', 'worn'),\n",
       " ('important', 'unimportant'),\n",
       " ('significant', 'insignificant'),\n",
       " ('other', 'same'),\n",
       " ('come', 'go'),\n",
       " ('arrive', 'leave'),\n",
       " ('similar', 'dissimilar'),\n",
       " ('like', 'unlike'),\n",
       " ('know', 'ignore'),\n",
       " ('known', 'unknown'),\n",
       " ('give', 'take'),\n",
       " ('feed', 'starve'),\n",
       " ('on', 'off'),\n",
       " ('begin', 'end'),\n",
       " ('start', 'stop'),\n",
       " ('holy', 'unholy'),\n",
       " ('home', 'away'),\n",
       " ('make', 'break'),\n",
       " ('have', 'lack'),\n",
       " ('consume', 'abstain'),\n",
       " ('accept', 'refuse'),\n",
       " ('add', 'subtract'),\n",
       " ('exclude', 'include'),\n",
       " ('differentiate', 'integrate'),\n",
       " ('original', 'unoriginal'),\n",
       " ('there', 'here'),\n",
       " ('wife', 'husband'),\n",
       " ('lose', 'keep'),\n",
       " ('lose', 'win'),\n",
       " ('lose', 'find'),\n",
       " ('lose', 'profit'),\n",
       " ('wind', 'unwind'),\n",
       " ('fair', 'foul'),\n",
       " ('fairly', 'unfairly'),\n",
       " ('buy', 'sell'),\n",
       " ('white', 'black'),\n",
       " ('whiten', 'blacken'),\n",
       " ('being', 'nonbeing'),\n",
       " ('existence', 'nonexistence'),\n",
       " ('continue', 'discontinue'),\n",
       " ('keep', 'lose'),\n",
       " ('prevent', 'let'),\n",
       " ('keep', 'break'),\n",
       " ('unbroken', 'broken'),\n",
       " ('possible', 'impossible'),\n",
       " ('potential', 'actual'),\n",
       " ('boil', 'freeze'),\n",
       " ('permanent', 'impermanent'),\n",
       " ('far', 'near'),\n",
       " ('more', 'less'),\n",
       " ('more', 'fewer'),\n",
       " ('loss', 'gain'),\n",
       " ('synonym', 'antonym'),\n",
       " ('possibly', 'impossibly'),\n",
       " ('early', 'middle'),\n",
       " ('early', 'late'),\n",
       " ('appear', 'disappear'),\n",
       " ('even', 'odd'),\n",
       " ('even', 'uneven'),\n",
       " ('innocent', 'guilty'),\n",
       " ('man', 'woman'),\n",
       " ('serviceman', 'civilian'),\n",
       " ('bequeath', 'disinherit'),\n",
       " ('quickly', 'slowly'),\n",
       " ('subsequent', 'antecedent'),\n",
       " ('complete', 'incomplete'),\n",
       " ('record', 'erase'),\n",
       " ('rush', 'linger'),\n",
       " ('square', 'round'),\n",
       " ('straight', 'crooked'),\n",
       " ('no', 'yes'),\n",
       " ('no', 'all'),\n",
       " ('ever', 'never'),\n",
       " ('general', 'particular'),\n",
       " ('general', 'specific'),\n",
       " ('general', 'local'),\n",
       " ('divide', 'unite'),\n",
       " ('typically', 'atypically'),\n",
       " ('traditional', 'nontraditional'),\n",
       " ('less', 'more'),\n",
       " ('expensive', 'cheap'),\n",
       " ('frequently', 'infrequently'),\n",
       " ('often', 'rarely'),\n",
       " ('change', 'stay'),\n",
       " ('precede', 'follow'),\n",
       " ('lower', 'raise'),\n",
       " ('low', 'high'),\n",
       " ('content', 'discontent'),\n",
       " ('contented', 'discontented'),\n",
       " ('commercial', 'noncommercial'),\n",
       " ('prepared', 'unprepared'),\n",
       " ('desegregate', 'segregate'),\n",
       " ('move', 'stay'),\n",
       " ('act', 'refrain'),\n",
       " ('moving', 'unmoving'),\n",
       " ('moving', 'still'),\n",
       " ('same', 'other'),\n",
       " ('same', 'different'),\n",
       " ('push', 'pull'),\n",
       " ('pull', 'push'),\n",
       " ('most', 'fewest'),\n",
       " ('most', 'least'),\n",
       " ('small', 'large'),\n",
       " ('little', 'big'),\n",
       " ('small', 'big'),\n",
       " ('free', 'confine'),\n",
       " ('unblock', 'block'),\n",
       " ('long', 'short'),\n",
       " ('thin', 'thicken'),\n",
       " ('reduce', 'gain'),\n",
       " ('thin', 'thick'),\n",
       " ('thin', 'fat'),\n",
       " ('thin', 'full'),\n",
       " ('thinly', 'thickly'),\n",
       " ('beginning', 'middle'),\n",
       " ('first', 'last'),\n",
       " ('first', 'second'),\n",
       " ('short', 'long'),\n",
       " ('short', 'tall'),\n",
       " ('local', 'express'),\n",
       " ('local', 'national'),\n",
       " ('local', 'general'),\n",
       " ('surface', 'subsurface'),\n",
       " ('soft', 'hard'),\n",
       " ('soft', 'loud'),\n",
       " ('voiced', 'unvoiced'),\n",
       " ('soft', 'hardened'),\n",
       " ('piano', 'forte'),\n",
       " ('natural', 'unnatural'),\n",
       " ('natural', 'artificial'),\n",
       " ('natural', 'supernatural'),\n",
       " ('natural', 'sharp'),\n",
       " ('cheap', 'expensive'),\n",
       " ('wellness', 'illness'),\n",
       " ('cooked', 'raw'),\n",
       " ('calm', 'agitate'),\n",
       " ('still', 'moving'),\n",
       " ('still', 'sparkling'),\n",
       " ('heat', 'cool'),\n",
       " ('internal', 'external'),\n",
       " ('least', 'most'),\n",
       " ('high', 'low'),\n",
       " ('fat', 'thin'),\n",
       " ('fatty', 'nonfat'),\n",
       " ('classified', 'unclassified'),\n",
       " ('level', 'raise'),\n",
       " ('establish', 'abolish'),\n",
       " ('find', 'lose'),\n",
       " ('found', 'lost'),\n",
       " ('refined', 'unrefined'),\n",
       " ('processed', 'unprocessed'),\n",
       " ('increase', 'decrease'),\n",
       " ('increment', 'decrement'),\n",
       " ('day', 'night'),\n",
       " ('probability', 'improbability'),\n",
       " ('shrink', 'stretch'),\n",
       " ('contract', 'expand'),\n",
       " ('narrow', 'widen'),\n",
       " ('criticize', 'praise'),\n",
       " ('necessitate', 'obviate'),\n",
       " ('demanding', 'undemanding'),\n",
       " ('software', 'hardware'),\n",
       " ('many', 'few'),\n",
       " ('illness', 'wellness'),\n",
       " ('properly', 'improperly'),\n",
       " ('promote', 'demote'),\n",
       " ('serious', 'frivolous'),\n",
       " ('adult', 'juvenile'),\n",
       " ('suppressed', 'publicized'),\n",
       " ('present', 'future'),\n",
       " ('present', 'absent'),\n",
       " ('child', 'parent'),\n",
       " ('young', 'old'),\n",
       " ('age', 'rejuvenate'),\n",
       " ('decreased', 'increased'),\n",
       " ('enforce', 'exempt'),\n",
       " ('convenience', 'inconvenience'),\n",
       " ('north', 'south'),\n",
       " ('national', 'international'),\n",
       " ('national', 'local'),\n",
       " ('prove', 'disprove'),\n",
       " ('show', 'hide'),\n",
       " ('strong', 'weak'),\n",
       " ('potent', 'impotent'),\n",
       " ('affinity', 'consanguinity'),\n",
       " ('topped', 'topless'),\n",
       " ('fresh', 'stale'),\n",
       " ('fresh', 'preserved'),\n",
       " ('fresh', 'salty'),\n",
       " ('bright', 'dull'),\n",
       " ('green', 'ripe'),\n",
       " ('wrapped', 'unwrapped'),\n",
       " ('old', 'young'),\n",
       " ('old', 'new'),\n",
       " ('continuous', 'discontinuous'),\n",
       " ('half', 'whole'),\n",
       " ('repel', 'attract'),\n",
       " ('directly', 'indirectly'),\n",
       " ('brother', 'sister'),\n",
       " ('like', 'dislike'),\n",
       " ('late', 'early'),\n",
       " ('outside', 'inside'),\n",
       " ('outdoor', 'indoor'),\n",
       " ('outdoors', 'indoors'),\n",
       " ('applied', 'theoretical'),\n",
       " ('stay', 'change'),\n",
       " ('rested', 'tired'),\n",
       " ('inside', 'outside'),\n",
       " ('official', 'unofficial'),\n",
       " ('center', 'right'),\n",
       " ('spread', 'gather'),\n",
       " ('unfold', 'fold'),\n",
       " ('organic', 'inorganic'),\n",
       " ('organic', 'functional'),\n",
       " ('sweeten', 'sour'),\n",
       " ('dry', 'wet'),\n",
       " ('ground', 'figure'),\n",
       " ('truth', 'falsity'),\n",
       " ('truth', 'falsehood'),\n",
       " ('accuracy', 'inaccuracy'),\n",
       " ('external', 'internal'),\n",
       " ('sweet', 'sour'),\n",
       " ('sweet', 'dry'),\n",
       " ('sour', 'sweeten'),\n",
       " ('sour', 'sweet'),\n",
       " ('reject', 'accept'),\n",
       " ('refuse', 'accept'),\n",
       " ('disapprove', 'approve'),\n",
       " ('reject', 'admit'),\n",
       " ('plausible', 'implausible'),\n",
       " ('patronize', 'boycott'),\n",
       " ('open', 'close'),\n",
       " ('open', 'closed'),\n",
       " ('hire', 'fire'),\n",
       " ('employed', 'unemployed'),\n",
       " ('literally', 'figuratively'),\n",
       " ('win', 'lose'),\n",
       " ('appearance', 'disappearance'),\n",
       " ('simple', 'complex'),\n",
       " ('simple', 'compound'),\n",
       " ('few', 'many'),\n",
       " ('living', 'dead'),\n",
       " ('attract', 'repel'),\n",
       " ('some', 'no'),\n",
       " ('specialize', 'diversify'),\n",
       " ('specialise', 'diversify'),\n",
       " ('specify', 'generalize'),\n",
       " ('specialized', 'unspecialized'),\n",
       " ('postwar', 'prewar'),\n",
       " ('defeat', 'victory'),\n",
       " ('war', 'peace'),\n",
       " ('military', 'civilian'),\n",
       " ('occupied', 'unoccupied'),\n",
       " ('recorded', 'live'),\n",
       " ('worst', 'best'),\n",
       " ('bad', 'good'),\n",
       " ('increased', 'decreased'),\n",
       " ('black', 'white'),\n",
       " ('blacken', 'whiten'),\n",
       " ('survive', 'succumb'),\n",
       " ('distribution', 'concentration'),\n",
       " ('function', 'malfunction'),\n",
       " ('run', 'idle'),\n",
       " ('east', 'west'),\n",
       " ('second', 'first'),\n",
       " ('familiar', 'unfamiliar'),\n",
       " ('familiar', 'strange'),\n",
       " ('private', 'public'),\n",
       " ('out', 'safe'),\n",
       " ('gain', 'loss'),\n",
       " ('gain', 'reduce'),\n",
       " ('prominence', 'obscurity'),\n",
       " ('urban', 'rural'),\n",
       " ('let', 'prevent'),\n",
       " ('permit', 'forbid'),\n",
       " ('allow', 'disallow'),\n",
       " ('allow', 'deny'),\n",
       " ('hit', 'miss'),\n",
       " ('regulate', 'deregulate'),\n",
       " ('order', 'disorder'),\n",
       " ('ordered', 'disordered'),\n",
       " ('coherent', 'incoherent'),\n",
       " ('standard', 'nonstandard'),\n",
       " ('wide', 'narrow'),\n",
       " ('geographic', 'magnetic'),\n",
       " ('difference', 'sameness'),\n",
       " ('broadly', 'narrowly'),\n",
       " ('independent', 'dependent'),\n",
       " ('basic', 'incidental'),\n",
       " ('alkaline', 'amphoteric'),\n",
       " ('well', 'ill'),\n",
       " ('well', 'badly'),\n",
       " ('different', 'same'),\n",
       " ('unlike', 'like'),\n",
       " ('inner', 'outer'),\n",
       " ('large', 'small'),\n",
       " ('big', 'little'),\n",
       " ('perfect', 'imperfect'),\n",
       " ('lend', 'borrow'),\n",
       " ('weak', 'strong'),\n",
       " ('up', 'down'),\n",
       " ('upwards', 'downwards'),\n",
       " ('upward', 'downward'),\n",
       " ('straight', 'curly'),\n",
       " ('uncoiled', 'coiled'),\n",
       " ('straight', 'curved'),\n",
       " ('popularity', 'unpopularity'),\n",
       " ('capacity', 'incapacity'),\n",
       " ('converge', 'diverge'),\n",
       " ('demand', 'supply'),\n",
       " ('better', 'worsen'),\n",
       " ('automatic', 'manual'),\n",
       " ('manual', 'automatic'),\n",
       " ('available', 'unavailable'),\n",
       " ('generally', 'specifically'),\n",
       " ('combined', 'uncombined'),\n",
       " ('divide', 'multiply'),\n",
       " ('divided', 'united'),\n",
       " ('clear', 'bounce'),\n",
       " ('acquit', 'convict'),\n",
       " ('clear', 'unclear'),\n",
       " ('clear', 'opaque'),\n",
       " ('clear', 'cloudy'),\n",
       " ('savory', 'unsavory'),\n",
       " ('reasonably', 'unreasonably'),\n",
       " ('light', 'dark'),\n",
       " ('ignite', 'extinguish'),\n",
       " ('light', 'heavy'),\n",
       " ('curly', 'straight'),\n",
       " ('adorned', 'unadorned'),\n",
       " ('usual', 'unusual'),\n",
       " ('lean', 'rich'),\n",
       " ('relative', 'absolute'),\n",
       " ('developed', 'undeveloped'),\n",
       " ('remember', 'forget'),\n",
       " ('born', 'unborn'),\n",
       " ('claim', 'disclaim'),\n",
       " ('claim', 'forfeit'),\n",
       " ('invest', 'divest'),\n",
       " ('seasoned', 'unseasoned'),\n",
       " ('thick', 'thin'),\n",
       " ('thickly', 'thinly'),\n",
       " ('express', 'local'),\n",
       " ('limited', 'unlimited'),\n",
       " ('end', 'begin'),\n",
       " ('finished', 'unfinished'),\n",
       " ('last', 'first'),\n",
       " ('go', 'come'),\n",
       " ('uppercase', 'lowercase'),\n",
       " ('rich', 'poor'),\n",
       " ('rich', 'lean'),\n",
       " ('finely', 'coarsely'),\n",
       " ('former', 'latter'),\n",
       " ('actual', 'potential'),\n",
       " ('difficult', 'easy'),\n",
       " ('hard', 'soft'),\n",
       " ('unvoiced', 'voiced'),\n",
       " ('heavily', 'lightly'),\n",
       " ('softness', 'hardness'),\n",
       " ('unfitness', 'fitness'),\n",
       " ('softness', 'loudness'),\n",
       " ('softness', 'sharpness'),\n",
       " ('left', 'right'),\n",
       " ('leave', 'arrive'),\n",
       " ('exit', 'enter'),\n",
       " ('left', 'center'),\n",
       " ('all', 'some'),\n",
       " ('wholly', 'partly'),\n",
       " ('fine', 'coarse'),\n",
       " ('hide', 'show'),\n",
       " ('agree', 'disagree'),\n",
       " ('love', 'hate'),\n",
       " ('related', 'unrelated'),\n",
       " ('follow', 'precede'),\n",
       " ('postdate', 'predate'),\n",
       " ('succeed', 'precede'),\n",
       " ('following', 'leading'),\n",
       " ('never', 'ever'),\n",
       " ('dress', 'undress'),\n",
       " ('separate', 'joint'),\n",
       " ('western', 'eastern'),\n",
       " ('cool', 'heat'),\n",
       " ('undress', 'dress'),\n",
       " ('location', 'studio'),\n",
       " ('paid', 'unpaid'),\n",
       " ('advance', 'retreat'),\n",
       " ('advance', 'recede'),\n",
       " ('advance', 'back'),\n",
       " ('progress', 'regress'),\n",
       " ('best', 'worst'),\n",
       " ('good', 'bad'),\n",
       " ('good', 'evil'),\n",
       " ('specialist', 'generalist'),\n",
       " ('miss', 'have'),\n",
       " ('fill', 'empty'),\n",
       " ('filled', 'unfilled'),\n",
       " ('export', 'import'),\n",
       " ('international', 'national'),\n",
       " ('likelihood', 'unlikelihood'),\n",
       " ('worsen', 'better'),\n",
       " ('warm', 'cool'),\n",
       " ('intended', 'unintended'),\n",
       " ('fold', 'unfold'),\n",
       " ('close', 'open'),\n",
       " ('notice', 'ignore'),\n",
       " ('improbable', 'probable'),\n",
       " ('unlikely', 'likely'),\n",
       " ('accelerate', 'decelerate'),\n",
       " ('south', 'north'),\n",
       " ('leafy', 'leafless'),\n",
       " ('specifically', 'generally'),\n",
       " ('naturally', 'unnaturally'),\n",
       " ('side', 'top'),\n",
       " ('salty', 'fresh'),\n",
       " ('little', 'much'),\n",
       " ('success', 'failure'),\n",
       " ('achiever', 'loser'),\n",
       " ('encourage', 'discourage'),\n",
       " ('queen', 'king'),\n",
       " ('ancestor', 'descendant'),\n",
       " ('cover', 'uncover'),\n",
       " ('covered', 'bare'),\n",
       " ('embark', 'disembark'),\n",
       " ('honor', 'dishonor'),\n",
       " ('respect', 'disrespect'),\n",
       " ('pleased', 'displeased'),\n",
       " ('here', 'there'),\n",
       " ('fast', 'slow'),\n",
       " ('rise', 'fall'),\n",
       " ('wax', 'wane'),\n",
       " ('rise', 'set'),\n",
       " ('rising', 'falling'),\n",
       " ('away', 'home'),\n",
       " ('expected', 'unexpected'),\n",
       " ('formal', 'informal'),\n",
       " ('raw', 'cooked'),\n",
       " ('likely', 'unlikely'),\n",
       " ('probable', 'improbable'),\n",
       " ('lodge', 'dislodge'),\n",
       " ('particular', 'general'),\n",
       " ('specific', 'general'),\n",
       " ('specific', 'nonspecific'),\n",
       " ('head', 'rear'),\n",
       " ('head', 'foot'),\n",
       " ('head', 'tail'),\n",
       " ('tonality', 'atonality'),\n",
       " ('bind', 'unbind'),\n",
       " ('tie', 'untie'),\n",
       " ('bound', 'unbound'),\n",
       " ('bound', 'free'),\n",
       " ('rarely', 'often'),\n",
       " ('close', 'distant'),\n",
       " ('near', 'far'),\n",
       " ('central', 'peripheral'),\n",
       " ('eastern', 'western'),\n",
       " ('southern', 'northern'),\n",
       " ('wholesome', 'unwholesome'),\n",
       " ('edible', 'inedible'),\n",
       " ('variable', 'invariable'),\n",
       " ('top', 'bottom'),\n",
       " ('seedless', 'seedy'),\n",
       " ('wild', 'tame'),\n",
       " ('scientific', 'unscientific'),\n",
       " ('cultivated', 'uncultivated'),\n",
       " ('native', 'foreign'),\n",
       " ('native', 'adopted'),\n",
       " ('native', 'nonnative'),\n",
       " ('primarily', 'secondarily'),\n",
       " ('lesser', 'greater'),\n",
       " ('sharp', 'dull'),\n",
       " ('sharp', 'flat'),\n",
       " ('useful', 'useless'),\n",
       " ('false', 'true'),\n",
       " ('tall', 'short'),\n",
       " ('dirty', 'clean'),\n",
       " ('goodness', 'evilness'),\n",
       " ('goodness', 'badness'),\n",
       " ('widen', 'narrow'),\n",
       " ('pack', 'unpack'),\n",
       " ('affirm', 'negate'),\n",
       " ('stop', 'start'),\n",
       " ('discontinue', 'continue'),\n",
       " ('indoors', 'outdoors'),\n",
       " ('inwardly', 'outwardly'),\n",
       " ('immature', 'mature'),\n",
       " ('individual', 'common'),\n",
       " ('single', 'double'),\n",
       " ('single', 'multiple'),\n",
       " ('unmarried', 'married'),\n",
       " ('whole', 'fractional'),\n",
       " ('whole', 'half'),\n",
       " ('incorrectly', 'correctly'),\n",
       " ('wrongly', 'right'),\n",
       " ('female', 'male'),\n",
       " ('female', 'androgynous'),\n",
       " ('male', 'female'),\n",
       " ('dry', 'sweet'),\n",
       " ('outer', 'inner'),\n",
       " ('lengthwise', 'crosswise'),\n",
       " ('decrease', 'increase'),\n",
       " ('atrophied', 'hypertrophied'),\n",
       " ('interior', 'exterior'),\n",
       " ('emit', 'absorb'),\n",
       " ('naturally', 'artificially'),\n",
       " ('public', 'private'),\n",
       " ('human', 'nonhuman'),\n",
       " ('take', 'give'),\n",
       " ('west', 'east'),\n",
       " ('pass', 'fail'),\n",
       " ('biological', 'adoptive'),\n",
       " ('classical', 'nonclassical'),\n",
       " ('selected', 'unselected'),\n",
       " ('issue', 'recall'),\n",
       " ('proved', 'unproved'),\n",
       " ('inadequate', 'adequate'),\n",
       " ('primary', 'secondary'),\n",
       " ('published', 'unpublished'),\n",
       " ('descendant', 'ancestor'),\n",
       " ('distinct', 'indistinct'),\n",
       " ('obviate', 'necessitate'),\n",
       " ('difficulty', 'ease'),\n",
       " ('inconsistency', 'consistency'),\n",
       " ('leading', 'following'),\n",
       " ('accept', 'reject'),\n",
       " ('varietal', 'generic'),\n",
       " ('enlist', 'discharge'),\n",
       " ('material', 'immaterial'),\n",
       " ('corporeal', 'incorporeal'),\n",
       " ('substantial', 'insubstantial'),\n",
       " ('pointed', 'pointless'),\n",
       " ('highland', 'lowland'),\n",
       " ('upland', 'lowland'),\n",
       " ('qualify', 'disqualify'),\n",
       " ('particular', 'universal'),\n",
       " ('much', 'little'),\n",
       " ('historical', 'ahistorical'),\n",
       " ('diachronic', 'synchronic'),\n",
       " ('recuperate', 'deteriorate'),\n",
       " ('northern', 'southern'),\n",
       " ('credibly', 'incredibly'),\n",
       " ('unsolved', 'solved'),\n",
       " ('linguistic', 'nonlinguistic'),\n",
       " ('absent', 'present'),\n",
       " ('sit', 'stand'),\n",
       " ('secondary', 'primary'),\n",
       " ('middle', 'end'),\n",
       " ('middle', 'late'),\n",
       " ('beginning', 'ending'),\n",
       " ('start', 'finish'),\n",
       " ('favorably', 'unfavorably'),\n",
       " ('extensive', 'intensive'),\n",
       " ('extraordinary', 'ordinary'),\n",
       " ('color', 'discolor'),\n",
       " ('double', 'single'),\n",
       " ('bivalent', 'multivalent'),\n",
       " ('civil', 'uncivil'),\n",
       " ('civil', 'sidereal'),\n",
       " ('involved', 'uninvolved'),\n",
       " ('evolution', 'devolution'),\n",
       " ('minor', 'major'),\n",
       " ('integrate', 'disintegrate'),\n",
       " ('integrate', 'differentiate'),\n",
       " ('integrated', 'segregated'),\n",
       " ('controlled', 'uncontrolled'),\n",
       " ('internally', 'externally'),\n",
       " ('host', 'parasite'),\n",
       " ('ascent', 'descent'),\n",
       " ('work', 'idle'),\n",
       " ('competition', 'cooperation'),\n",
       " ('interest', 'bore'),\n",
       " ('cold', 'hot'),\n",
       " ('favorable', 'unfavorable'),\n",
       " ('majority', 'minority'),\n",
       " ('leader', 'follower'),\n",
       " ('windward', 'leeward'),\n",
       " ('downwind', 'upwind'),\n",
       " ('engage', 'disengage'),\n",
       " ('vulnerable', 'invulnerable'),\n",
       " ('descend', 'ascend'),\n",
       " ('fall', 'rise'),\n",
       " ('diploid', 'polyploid'),\n",
       " ('polyploid', 'haploid'),\n",
       " ('immediate', 'mediate'),\n",
       " ('due', 'undue'),\n",
       " ('attack', 'defend'),\n",
       " ('fear', 'fearlessness'),\n",
       " ('extinct', 'extant'),\n",
       " ('extinct', 'active'),\n",
       " ('danger', 'safety'),\n",
       " ('impossible', 'possible'),\n",
       " ('supply', 'demand'),\n",
       " ('unclear', 'clear'),\n",
       " ('existent', 'nonexistent'),\n",
       " ('tense', 'relax'),\n",
       " ('artificial', 'natural'),\n",
       " ('affected', 'unaffected'),\n",
       " ('moved', 'unmoved'),\n",
       " ('permanently', 'temporarily'),\n",
       " ('break', 'repair'),\n",
       " ('break', 'keep'),\n",
       " ('break', 'make'),\n",
       " ('demote', 'promote'),\n",
       " ('ripe', 'green'),\n",
       " ('domestic', 'foreign'),\n",
       " ('treated', 'untreated'),\n",
       " ('reported', 'unreported'),\n",
       " ('uncover', 'cover'),\n",
       " ('stabilize', 'destabilize'),\n",
       " ('stabilise', 'destabilise'),\n",
       " ('maximum', 'minimum'),\n",
       " ('maximal', 'minimal'),\n",
       " ('careful', 'careless'),\n",
       " ('concentration', 'distribution'),\n",
       " ('concentration', 'dilution'),\n",
       " ('distributed', 'concentrated'),\n",
       " ('exploited', 'unexploited'),\n",
       " ('sealed', 'unsealed'),\n",
       " ('aquatic', 'terrestrial'),\n",
       " ('deprive', 'enrich'),\n",
       " ('expand', 'contract'),\n",
       " ('cut', 'uncut'),\n",
       " ('trimmed', 'untrimmed'),\n",
       " ('down', 'up'),\n",
       " ('downwards', 'upwards'),\n",
       " ('downward', 'upward'),\n",
       " ('waste', 'conserve'),\n",
       " ('major', 'minor'),\n",
       " ('defend', 'prosecute'),\n",
       " ('valuable', 'worthless'),\n",
       " ('source', 'sink'),\n",
       " ('suffer', 'enjoy'),\n",
       " ('blame', 'absolve'),\n",
       " ('decline', 'improvement'),\n",
       " ('descent', 'ascent'),\n",
       " ('enter', 'exit'),\n",
       " ('off', 'on'),\n",
       " ('infect', 'disinfect'),\n",
       " ('destroyed', 'preserved'),\n",
       " ('preventive', 'permissive'),\n",
       " ('defense', 'offense'),\n",
       " ('defence', 'offence'),\n",
       " ('defense', 'prosecution'),\n",
       " ('enrich', 'deprive'),\n",
       " ('enrich', 'impoverish'),\n",
       " ('focus', 'blur'),\n",
       " ('septic', 'antiseptic'),\n",
       " ('obstruct', 'free'),\n",
       " ('starve', 'feed'),\n",
       " ('addition', 'subtraction'),\n",
       " ('question', 'answer'),\n",
       " ('intensive', 'extensive'),\n",
       " ('dark', 'light'),\n",
       " ('night', 'day'),\n",
       " ('effectively', 'ineffectively'),\n",
       " ('democratic', 'undemocratic'),\n",
       " ('narrow', 'wide'),\n",
       " ('full', 'empty'),\n",
       " ('full', 'thin'),\n",
       " ('conserve', 'waste'),\n",
       " ('manage', 'fail'),\n",
       " ('liquid', 'gaseous'),\n",
       " ('unmanageable', 'manageable'),\n",
       " ('improvement', 'decline'),\n",
       " ('mushroom', 'toadstool'),\n",
       " ('dehydrate', 'hydrate'),\n",
       " ('experience', 'inexperience'),\n",
       " ('indirectly', 'directly'),\n",
       " ('stimulate', 'stifle'),\n",
       " ('stimulate', 'sedate'),\n",
       " ('soften', 'sharpen'),\n",
       " ('yield', 'stand'),\n",
       " ('soften', 'harden'),\n",
       " ('deep', 'shallow'),\n",
       " ('intense', 'mild'),\n",
       " ('con', 'pro'),\n",
       " ('friendly', 'hostile'),\n",
       " ('friendly', 'unfriendly'),\n",
       " ('tender', 'tough'),\n",
       " ('succumb', 'survive'),\n",
       " ('differ', 'equal'),\n",
       " ('disagree', 'agree'),\n",
       " ('desirable', 'undesirable'),\n",
       " ('written', 'spoken'),\n",
       " ('written', 'unwritten'),\n",
       " ('scripted', 'unscripted'),\n",
       " ('physical', 'mental'),\n",
       " ('comedy', 'tragedy'),\n",
       " ('foot', 'head'),\n",
       " ('boy', 'girl'),\n",
       " ('son', 'daughter'),\n",
       " ('grateful', 'ungrateful'),\n",
       " ('conception', 'misconception'),\n",
       " ('hungry', 'thirsty'),\n",
       " ('belief', 'unbelief'),\n",
       " ('tied', 'untied'),\n",
       " ('approval', 'disapproval'),\n",
       " ('bless', 'curse'),\n",
       " ('consecrate', 'desecrate'),\n",
       " ('couple', 'uncouple'),\n",
       " ('certain', 'uncertain'),\n",
       " ('sure', 'unsure'),\n",
       " ('inhabited', 'uninhabited'),\n",
       " ('young', 'aged'),\n",
       " ('colored', 'uncolored'),\n",
       " ('hate', 'love'),\n",
       " ('elective', 'appointive'),\n",
       " ('woman', 'man'),\n",
       " ('capability', 'incapability'),\n",
       " ('heavy', 'light'),\n",
       " ('metallic', 'nonmetallic'),\n",
       " ('contamination', 'decontamination'),\n",
       " ('nuclear', 'conventional'),\n",
       " ('functional', 'nonfunctional'),\n",
       " ('functional', 'organic'),\n",
       " ('partial', 'impartial'),\n",
       " ('valid', 'invalid'),\n",
       " ('set', 'rise'),\n",
       " ('right', 'left'),\n",
       " ('right', 'wrong'),\n",
       " ('correct', 'falsify'),\n",
       " ('correct', 'incorrect'),\n",
       " ('correctly', 'incorrectly'),\n",
       " ('right', 'wrongly'),\n",
       " ('closed', 'open'),\n",
       " ('shut', 'open'),\n",
       " ('indeterminate', 'determinate'),\n",
       " ('gather', 'spread'),\n",
       " ('collected', 'uncollected'),\n",
       " ('explicitly', 'implicitly'),\n",
       " ('passing', 'failing'),\n",
       " ('passing', 'running'),\n",
       " ('equivocal', 'unequivocal'),\n",
       " ('ambiguous', 'unambiguous'),\n",
       " ('enforced', 'unenforced'),\n",
       " ('above', 'below'),\n",
       " ('fewer', 'more'),\n",
       " ('forget', 'remember'),\n",
       " ('block', 'unblock'),\n",
       " ('universal', 'particular'),\n",
       " ('explicit', 'implicit'),\n",
       " ('precise', 'imprecise'),\n",
       " ('compress', 'decompress'),\n",
       " ('compact', 'loose'),\n",
       " ('open', 'shut'),\n",
       " ('receptive', 'unreceptive'),\n",
       " ('overt', 'covert'),\n",
       " ('freeze', 'boil'),\n",
       " ('frozen', 'unfrozen'),\n",
       " ('solid', 'liquid'),\n",
       " ('solid', 'hollow'),\n",
       " ('presence', 'absence'),\n",
       " ('impurity', 'purity'),\n",
       " ('opaque', 'clear'),\n",
       " ('abundant', 'scarce'),\n",
       " ('polar', 'equatorial'),\n",
       " ('looseness', 'tightness'),\n",
       " ('slowly', 'quickly'),\n",
       " ('below', 'above'),\n",
       " ('downstairs', 'upstairs'),\n",
       " ('crystalline', 'noncrystalline'),\n",
       " ('cubic', 'linear'),\n",
       " ('deposit', 'withdraw'),\n",
       " ('inorganic', 'organic'),\n",
       " ('regular', 'irregular'),\n",
       " ('critical', 'uncritical'),\n",
       " ('unusual', 'usual'),\n",
       " ('strange', 'familiar'),\n",
       " ('expansion', 'contraction'),\n",
       " ('decreasing', 'increasing'),\n",
       " ('loudness', 'softness'),\n",
       " ('explode', 'implode'),\n",
       " ('float', 'sink'),\n",
       " ('bottom', 'top'),\n",
       " ('bottom', 'side'),\n",
       " ('sufficiently', 'insufficiently'),\n",
       " ('absorb', 'emit'),\n",
       " ('constant', 'inconstant'),\n",
       " ('broken', 'unbroken'),\n",
       " ('end', 'beginning'),\n",
       " ('increasing', 'decreasing'),\n",
       " ('precisely', 'imprecisely'),\n",
       " ('defined', 'undefined'),\n",
       " ('absolute', 'relative'),\n",
       " ('changed', 'unchanged'),\n",
       " ('responsible', 'irresponsible'),\n",
       " ('formed', 'unformed'),\n",
       " ('compression', 'decompression'),\n",
       " ('ordinary', 'extraordinary'),\n",
       " ('stable', 'unstable'),\n",
       " ('dislodge', 'lodge'),\n",
       " ('exempt', 'enforce'),\n",
       " ('free', 'obstruct'),\n",
       " ('absolve', 'blame'),\n",
       " ('free', 'unfree'),\n",
       " ('free', 'bound'),\n",
       " ('significance', 'insignificance'),\n",
       " ('standing', 'running'),\n",
       " ('standing', 'seated'),\n",
       " ('quantitative', 'qualitative'),\n",
       " ('quantitative', 'syllabic'),\n",
       " ('tire', 'refresh'),\n",
       " ('bore', 'interest'),\n",
       " ('active', 'inactive'),\n",
       " ('active', 'passive'),\n",
       " ('active', 'quiet'),\n",
       " ('active', 'stative'),\n",
       " ('active', 'extinct'),\n",
       " ('active', 'dormant'),\n",
       " ('hydrate', 'dehydrate'),\n",
       " ('repair', 'break'),\n",
       " ('fixed', 'unfixed'),\n",
       " ('attach', 'detach'),\n",
       " ('attached', 'detached'),\n",
       " ('attached', 'unattached'),\n",
       " ('opening', 'closing'),\n",
       " ('normal', 'abnormal'),\n",
       " ('normal', 'paranormal'),\n",
       " ('discharge', 'charge'),\n",
       " ('discharge', 'enlist'),\n",
       " ('empty', 'fill'),\n",
       " ('sedate', 'stimulate'),\n",
       " ('calm', 'stormy'),\n",
       " ('exclude', 'admit'),\n",
       " ('round', 'square'),\n",
       " ('parallel', 'perpendicular'),\n",
       " ('sink', 'float'),\n",
       " ('loaded', 'unloaded'),\n",
       " ('perpendicular', 'oblique'),\n",
       " ('vertical', 'inclined'),\n",
       " ('flatten', 'sharpen'),\n",
       " ('deteriorate', 'recuperate'),\n",
       " ('pure', 'impure'),\n",
       " ('saturated', 'unsaturated'),\n",
       " ('bounce', 'clear'),\n",
       " ('falling', 'rising'),\n",
       " ('rear', 'front'),\n",
       " ('back', 'front'),\n",
       " ('back', 'advance'),\n",
       " ('back', 'veer'),\n",
       " ('backward', 'forward'),\n",
       " ('back', 'ahead'),\n",
       " ('front', 'rear'),\n",
       " ('front', 'back'),\n",
       " ('raise', 'lower'),\n",
       " ('supported', 'unsupported'),\n",
       " ('identifiable', 'unidentifiable'),\n",
       " ('maximize', 'minimize'),\n",
       " ('maximise', 'minimise'),\n",
       " ('greater', 'lesser'),\n",
       " ('able', 'unable'),\n",
       " ('efficient', 'inefficient'),\n",
       " ('poor', 'rich'),\n",
       " ('infield', 'outfield'),\n",
       " ('efficiency', 'inefficiency'),\n",
       " ('linearly', 'geometrically'),\n",
       " ('equal', 'unequal'),\n",
       " ('adequate', 'inadequate'),\n",
       " ('activity', 'inactivity'),\n",
       " ('action', 'inaction'),\n",
       " ('trust', 'mistrust'),\n",
       " ('distant', 'close'),\n",
       " ('considerable', 'inconsiderable'),\n",
       " ('sent', 'unsent'),\n",
       " ('big', 'small'),\n",
       " ('better', 'worse'),\n",
       " ('service', 'disservice'),\n",
       " ('concrete', 'abstract'),\n",
       " ('safe', 'dangerous'),\n",
       " ('safe', 'out'),\n",
       " ('dangerous', 'safe'),\n",
       " ('stay', 'move'),\n",
       " ('stay', 'depart'),\n",
       " ('sufficient', 'insufficient'),\n",
       " ('vulnerability', 'invulnerability'),\n",
       " ('damaged', 'undamaged'),\n",
       " ('exact', 'inexact'),\n",
       " ('reverse', 'obverse'),\n",
       " ('reverse', 'forward'),\n",
       " ('attention', 'inattention'),\n",
       " ('modified', 'unmodified'),\n",
       " ('cool', 'warm'),\n",
       " ('power', 'powerlessness'),\n",
       " ('ability', 'inability'),\n",
       " ('pain', 'pleasure'),\n",
       " ('strength', 'weakness'),\n",
       " ('sound', 'silence'),\n",
       " ('sound', 'unsound'),\n",
       " ('practical', 'impractical'),\n",
       " ('impermanent', 'permanent'),\n",
       " ('regularly', 'irregularly'),\n",
       " ('ease', 'difficulty'),\n",
       " ('volatile', 'nonvolatile'),\n",
       " ('lie', 'stand'),\n",
       " ('magnetic', 'nonmagnetic'),\n",
       " ('magnetic', 'geographic'),\n",
       " ('obey', 'disobey'),\n",
       " ('energetic', 'lethargic'),\n",
       " ('ripeness', 'greenness'),\n",
       " ('acidic', 'alkaline'),\n",
       " ('benign', 'malignant'),\n",
       " ('benign', 'malign'),\n",
       " ('healthy', 'unhealthy'),\n",
       " ('credible', 'incredible'),\n",
       " ('equatorial', 'polar'),\n",
       " ('legal', 'illegal'),\n",
       " ('borrow', 'lend'),\n",
       " ('repute', 'disrepute'),\n",
       " ('direct', 'indirect'),\n",
       " ('lineal', 'collateral'),\n",
       " ('direct', 'retrograde'),\n",
       " ('direct', 'inverse'),\n",
       " ('direct', 'alternating'),\n",
       " ('noticed', 'unnoticed'),\n",
       " ('agitate', 'calm'),\n",
       " ('excited', 'unexcited'),\n",
       " ('ill', 'well'),\n",
       " ('expatriate', 'repatriate'),\n",
       " ('fragrant', 'malodorous'),\n",
       " ('awake', 'asleep'),\n",
       " ('religious', 'irreligious'),\n",
       " ('religious', 'secular'),\n",
       " ('credit', 'debit'),\n",
       " ('credit', 'cash'),\n",
       " ('king', 'queen'),\n",
       " ('horned', 'hornless'),\n",
       " ('advantage', 'disadvantage'),\n",
       " ('reward', 'penalty'),\n",
       " ('protected', 'unprotected'),\n",
       " ('smooth', 'rough'),\n",
       " ('legato', 'staccato'),\n",
       " ('clement', 'inclement'),\n",
       " ('defeated', 'undefeated'),\n",
       " ('successful', 'unsuccessful'),\n",
       " ('alcoholic', 'nonalcoholic'),\n",
       " ('scarce', 'abundant'),\n",
       " ('raise', 'level'),\n",
       " ('accessibility', 'inaccessibility'),\n",
       " ('availability', 'unavailability'),\n",
       " ('resolution', 'preparation'),\n",
       " ('avoid', 'confront'),\n",
       " ('invalidate', 'validate'),\n",
       " ('temporarily', 'permanently'),\n",
       " ('latter', 'former'),\n",
       " ('cleared', 'uncleared'),\n",
       " ('coarse', 'fine'),\n",
       " ('bloody', 'bloodless'),\n",
       " ('ready', 'unready'),\n",
       " ('egalitarian', 'elitist'),\n",
       " ('matched', 'mismatched'),\n",
       " ('comparable', 'incomparable'),\n",
       " ('cash', 'credit'),\n",
       " ('dependent', 'independent'),\n",
       " ('evergreen', 'deciduous'),\n",
       " ('antonym', 'synonym'),\n",
       " ('opposite', 'alternate'),\n",
       " ('fuse', 'defuse'),\n",
       " ('inferior', 'superior'),\n",
       " ('subscript', 'superscript'),\n",
       " ('fail', 'succeed'),\n",
       " ('fail', 'manage'),\n",
       " ('fail', 'pass'),\n",
       " ('effective', 'ineffective'),\n",
       " ('tributary', 'distributary'),\n",
       " ('idle', 'work'),\n",
       " ('sensitive', 'insensitive'),\n",
       " ('sensible', 'insensible'),\n",
       " ('invertebrate', 'vertebrate'),\n",
       " ('parasite', 'host'),\n",
       " ('ineffective', 'effective'),\n",
       " ('juvenile', 'adult'),\n",
       " ('insectivorous', 'carnivorous'),\n",
       " ('alignment', 'nonalignment'),\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foodAntonyms=creatAntonymsFromCategory(str(foodCorpus),word2vec)\n",
    "#foodAntonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the survey, the results stored here are mostly used in the final paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToStandardScore(data):\n",
    "    #mean=np.mean(data)\n",
    "    mean=0 # should be 0\n",
    "    #std=np.std(data)\n",
    "    std=0\n",
    "    for i in data:\n",
    "        std+=(i-mean)**2\n",
    "    std=np.sqrt(std/len(data))\n",
    "    test=(data-mean)/std\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.6376057 -2.4719634  2.1037996  2.0349684 -1.964916   3.3981974\n",
      "  2.8098958 -2.2330103  2.0785902  1.8684635  3.0543187  2.5934815\n",
      " -2.1792395 -2.1180494  1.9136409 -3.6438596  2.4659219 -2.4528916\n",
      "  2.438985   1.9591951 -8.014288  -2.492912  -1.8954415  1.6020002\n",
      "  1.4259257 -2.123254   2.0785973  1.8416966 -1.7187723  1.661742 ]\n",
      "Mean of root antonyms:  0.04610721666666669\n",
      "Mean of absolute values of root antonyms:  2.4425207700000002\n",
      "Standard deviation of root antonyms:  2.6978974547361676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.97750958, -0.91612173,  0.77967843,  0.75416925, -0.72820748,\n",
       "        1.25938858,  1.04136113, -0.82756454,  0.7703357 ,  0.69246172,\n",
       "        1.13194545,  0.96115693, -0.80763682, -0.78495947,  0.70920468,\n",
       "       -1.3504322 ,  0.91388272, -0.90905363,  0.90389977,  0.72608729,\n",
       "       -2.97013435, -0.92388538, -0.70245989,  0.59370911,  0.52845504,\n",
       "       -0.78688832,  0.77033833,  0.68254177, -0.63698542,  0.61584972])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#results from POLAR\n",
    "usaRegular=[-2.6376057, -2.4719634, 2.1037996, 2.0349684, -1.964916]\n",
    "germanyRegular=[3.3981974, 2.8098958, -2.2330103,2.0785902,1.8684635]\n",
    "saladRegular=[3.0543187,2.5934815,-2.1792395,-2.1180494,1.9136409]\n",
    "riceRegular=[-3.6438596,2.4659219,-2.4528916,2.438985,1.9591951]\n",
    "popRegular=[-8.014288,-2.492912,-1.8954415,1.6020002,1.4259257]\n",
    "rammsteinRegular=[-2.123254,2.0785973,1.8416966,-1.7187723,1.661742]\n",
    "\n",
    "regular=usaRegular+germanyRegular+saladRegular+riceRegular+popRegular+rammsteinRegular\n",
    "regularCounty=usaRegular+germanyRegular\n",
    "regularFood=saladRegular+riceRegular\n",
    "regularMusic=popRegular+rammsteinRegular\n",
    "regular=np.array(regular)\n",
    "\n",
    "signRegular=np.sign(regular)\n",
    "\n",
    "regularABS=abs(regular)\n",
    "print(regular)\n",
    "regularMean=np.mean(regular)\n",
    "regularMeanAbs=np.mean(regularABS)\n",
    "regularSTD=np.std(regular)\n",
    "print(\"Mean of root antonyms: \",regularMean)\n",
    "print(\"Mean of absolute values of root antonyms: \",regularMeanAbs)\n",
    "print(\"Standard deviation of root antonyms: \",regularSTD)\n",
    "normalizedRegular=transformToStandardScore(regular)\n",
    "display(normalizedRegular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2503996 -3.057242  -3.0330684  2.7474287  2.7222674  4.52079\n",
      " -3.6331446  3.2978609  3.2470224  2.7367115 -3.5309575 -2.9052043\n",
      " -2.8565931  2.8449438 -2.8341067  3.999362   3.8820155 -3.8019125\n",
      "  3.7979877  3.584927  -3.0669188 -2.4912317  2.339505  -2.2503352\n",
      "  2.2032032 -3.0293212 -2.3457592  2.047324   2.047324   1.9114097]\n",
      "Mean of root antonyms:  0.19479626666666663\n",
      "Mean of absolute values of root antonyms:  3.0005425866666666\n",
      "Standard deviation of root antonyms:  3.0615208001082967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.05955184, -0.99658712, -0.98870711,  0.89559546,  0.88739349,\n",
       "        1.47366846, -1.18431748,  1.07502308,  1.05845096,  0.89210192,\n",
       "       -1.15100695, -0.9470265 , -0.93118042,  0.92738303, -0.9238504 ,\n",
       "        1.30369551,  1.26544338, -1.23933174,  1.23805235,  1.1685997 ,\n",
       "       -0.99974153, -0.81208142,  0.76262218, -0.73355498,  0.71819108,\n",
       "       -0.98748562, -0.7646609 ,  0.66737822,  0.66737822,  0.62307344])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results from Polar\n",
    "usaExtended=[-3.2503996,-3.057242,-3.0330684,2.7474287,2.7222674]\n",
    "germanyExtended=[4.52079,-3.6331446,3.2978609,3.2470224,2.7367115]\n",
    "saladExtended=[-3.5309575,-2.9052043,-2.8565931,2.8449438,-2.8341067]\n",
    "riceExtended=[3.999362,3.8820155,-3.8019125,3.7979877,3.584927]\n",
    "popExtended=[-3.0669188,-2.4912317,2.339505,-2.2503352,2.2032032]\n",
    "rammsteinExtended=[-3.0293212,-2.3457592,2.047324,2.047324,1.9114097]\n",
    "\n",
    "\n",
    "extended=usaExtended+germanyExtended+saladExtended+riceExtended+popExtended+rammsteinExtended\n",
    "extendedCounty=usaExtended+germanyExtended\n",
    "extendedFood=saladExtended+riceExtended\n",
    "extendedMusic=popExtended+rammsteinExtended\n",
    "\n",
    "extended=np.array(extended)\n",
    "\n",
    "signExtended=np.sign(extended)\n",
    "\n",
    "extendedABS=abs(extended)\n",
    "print(extended)\n",
    "extendedMean=np.mean(extended)\n",
    "extendedMeanAbs=np.mean(extendedABS)\n",
    "extendedSTD=np.std(extended)\n",
    "print(\"Mean of root antonyms: \",extendedMean)\n",
    "print(\"Mean of absolute values of root antonyms: \",extendedMeanAbs)\n",
    "print(\"Standard deviation of root antonyms: \",extendedSTD)\n",
    "normalizedExtended=transformToStandardScore(extended)\n",
    "display(normalizedExtended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2503996 -3.057242  -3.0330684  2.7474287  2.7222674  4.52079\n",
      " -3.6331446  3.2978609  3.2470224  2.7367115 -3.5309575 -2.9052043\n",
      " -2.8565931  2.8449438 -2.8341067  3.999362   3.8820155 -3.8019125\n",
      "  3.7979877  3.584927  -3.0669188 -2.4912317  2.339505  -2.2503352\n",
      "  2.2032032 -3.0293212 -2.3457592  2.047324   2.047324   1.9114097]\n",
      "[-2.6376057, -2.4719634, 2.1037996, 2.0349684, -1.964916, -3.2503996, -3.057242, -3.0330684, 2.7474287, 2.7222674, 3.3981974, 2.8098958, -2.2330103, 2.0785902, 1.8684635, 4.52079, -3.6331446, 3.2978609, 3.2470224, 2.7367115, 3.0543187, 2.5934815, -2.1792395, -2.1180494, 1.9136409, -3.5309575, -2.9052043, -2.8565931, 2.8449438, -2.8341067, -3.6438596, 2.4659219, -2.4528916, 2.438985, 1.9591951, 3.999362, 3.8820155, -3.8019125, 3.7979877, 3.584927, -8.014288, -2.492912, -1.8954415, 1.6020002, 1.4259257, -3.0669188, -2.4912317, 2.339505, -2.2503352, 2.2032032, -2.123254, 2.0785973, 1.8416966, -1.7187723, 1.661742, -3.0293212, -2.3457592, 2.047324, 2.047324, 1.9114097]\n"
     ]
    }
   ],
   "source": [
    "regularPolar=regular\n",
    "extendedPolar=extended\n",
    "print(extendedPolar)\n",
    "allAnswerPolar=allAnswer=usaRegular+usaExtended+germanyRegular+germanyExtended+saladRegular+saladExtended+riceRegular+riceExtended+popRegular+popExtended+rammsteinRegular+rammsteinExtended\n",
    "print(allAnswerPolar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x00000214B851F518>\n",
      "Number of Participants: 30.\n",
      "30\n",
      "[4.86666667 6.06666667 4.23333333 7.66666667 6.8        2.83333333\n",
      " 4.         7.13333333 2.4        3.43333333 6.2        4.2\n",
      " 3.16666667 7.16666667 5.06666667 4.93333333 6.66666667 5.9\n",
      " 4.13333333 7.         6.53333333 6.1        5.06666667 0.9\n",
      " 5.86666667 6.2        4.9        1.53333333 7.53333333 3.16666667\n",
      " 1.2        5.1        1.63333333 7.86666667 6.06666667 7.8\n",
      " 7.13333333 3.56666667 3.33333333 3.66666667 0.56666667 2.9\n",
      " 7.63333333 6.4        7.93333333 1.86666667 5.16666667 5.46666667\n",
      " 4.2        5.5        2.6        8.33333333 5.76666667 4.5\n",
      " 3.56666667 5.33333333 5.1        5.23333333 4.36666667 6.16666667]\n",
      "[1.92757764 2.74388208 1.94393644 2.07096328 2.35796522 2.00138841\n",
      " 2.5560386  2.14061258 1.74355958 2.18606699 1.30128142 1.93907194\n",
      " 2.14605581 1.48511129 2.18987569 1.28927197 1.77638835 2.31444738\n",
      " 1.80246744 2.         2.26175939 1.3        2.27937613 1.07548439\n",
      " 3.06304134 1.72046505 2.25610283 1.5860503  1.74610678 1.93362067\n",
      " 1.53622915 1.57797338 2.18301524 2.07739153 2.82764134 1.55777619\n",
      " 1.78387842 1.87409237 3.01477841 2.00554786 0.88254682 1.77670106\n",
      " 1.99137027 2.02649122 1.33998342 2.15612822 2.35348441 2.48640749\n",
      " 2.2420229  1.78418983 1.81842423 1.22020035 2.60362994 2.60448331\n",
      " 1.78294388 1.67994709 2.7        1.80154255 2.27278586 2.06693547]\n"
     ]
    }
   ],
   "source": [
    "# Results from the survey, stored in Survey/RatingCsv.csv\n",
    "\n",
    "import csv\n",
    "\n",
    "ratingsNormal=[]\n",
    "ratings=[]\n",
    "\n",
    "with open('Survey/RatingCsv.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    print(csv_reader)\n",
    "    line_count=0\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            #print(\"new Row\")\n",
    "            #print(row[3:63]) #60 questions\n",
    "            curRatings=row[3:63]\n",
    "            curIntRatingNormal=[]\n",
    "            curIntRating=[]\n",
    "            for string in curRatings:\n",
    "                curIntRatingNormal.append(int(string))\n",
    "                curIntRating.append(int(string)-5)\n",
    "            \n",
    "            ratings.append(curIntRating)\n",
    "            ratingsNormal.append(curIntRatingNormal)\n",
    "            line_count += 1\n",
    "    print(f'Number of Participants: {line_count-1}.')\n",
    "    \n",
    "\n",
    "print(len(ratings))\n",
    "meanSurvey=np.mean(ratingsNormal, axis=0) #ratings answersNormalized\n",
    "stdSurvey=np.std(ratingsNormal, axis=0) #ratings answersNormalized\n",
    "print(meanSurvey)\n",
    "print(stdSurvey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize all answers\n",
    "answersNormalized=[transformToStandardScore(np.array(answer)) for answer in ratings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break them down into answers to hand-crafted questions and extended pairs of antonyms\n",
    "answersRegular=[]\n",
    "answersExtended=[]\n",
    "\n",
    "for answer in answersNormalized:\n",
    "    participantReg=[]\n",
    "    participantExt=[]\n",
    "    reg=[]\n",
    "    ext=[]\n",
    "    counter=0\n",
    "    curList=reg\n",
    "    for rating in answer:\n",
    "        curList.append(rating)\n",
    "        counter+=1\n",
    "        if counter==5:\n",
    "            participantReg.append(reg)\n",
    "            reg=[]\n",
    "            curList=ext\n",
    "        if counter==10:\n",
    "            participantExt.append(ext)\n",
    "            ext=[]\n",
    "            curList=reg\n",
    "            counter=0\n",
    "        \n",
    "    answersRegular.append(participantReg)\n",
    "    answersExtended.append(participantExt)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not normalized!!!!!\n",
    "answersRegularNN=[]\n",
    "answersExtendedNN=[]\n",
    "\n",
    "for answer in ratings:\n",
    "    participantReg=[]\n",
    "    participantExt=[]\n",
    "    reg=[]\n",
    "    ext=[]\n",
    "    counter=0\n",
    "    curList=reg\n",
    "    for rating in answer:\n",
    "        curList.append(rating)\n",
    "        counter+=1\n",
    "        if counter==5:\n",
    "            participantReg.append(reg)\n",
    "            reg=[]\n",
    "            curList=ext\n",
    "        if counter==10:\n",
    "            participantExt.append(ext)\n",
    "            ext=[]\n",
    "            curList=reg\n",
    "            counter=0\n",
    "        \n",
    "    answersRegularNN.append(participantReg)\n",
    "    answersExtendedNN.append(participantExt)\n",
    "    #print(len(answersRegular))\n",
    "    #print(len(answersRegular[0]))\n",
    "    #print(len(answersExtended))\n",
    "    #print(len(answersExtended[0]))\n",
    "    #break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distance from 5. Are the Antonym pairs relevent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageDistanceFrom5(answers):\n",
    "    avgDistance=0\n",
    "    for answer in answers:\n",
    "        flatAnswer = [item for sublist in answer for item in sublist]\n",
    "        dist=[abs(entry) for entry in flatAnswer]\n",
    "        avgDistance+=np.sum(dist)\n",
    "    dist=avgDistance/(len(answersRegularNN)*len(flatAnswer))    \n",
    "    #print(\"Average distance from 5 is: \", dist) # 30*30\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "distRegular=computeAverageDistanceFrom5(answersRegularNN)   \n",
    "distExtended=computeAverageDistanceFrom5(answersExtendedNN) \n",
    "\n",
    "regAnswerCountry=[country[0:2] for country in answersRegularNN]\n",
    "extAnswerCountry=[country[0:2] for country in answersExtendedNN]\n",
    "regAnswerFood=[food[2:4] for food in answersRegularNN]\n",
    "extAnswerFood=[food[2:4] for food in answersExtendedNN]\n",
    "regAnswerMusic=[music[4:6] for music in answersRegularNN]\n",
    "extAnswerMusic=[music[4:6] for music in answersExtendedNN]\n",
    "\n",
    "distRegCountry=computeAverageDistanceFrom5(regAnswerCountry)   \n",
    "distExtCountry=computeAverageDistanceFrom5(extAnswerCountry) \n",
    "distRegFood=computeAverageDistanceFrom5(regAnswerFood)   \n",
    "distExtFood=computeAverageDistanceFrom5(extAnswerFood) \n",
    "distRegMusic=computeAverageDistanceFrom5(regAnswerMusic)   \n",
    "distExtMusic=computeAverageDistanceFrom5(extAnswerMusic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance from 5 of all regular is:  2.45\n",
      "Average distance from 5 of all extended is:  2.082222222222222\n",
      "\n",
      "Average distance from 5 of reg Country is:  2.1033333333333335\n",
      "Average distance from 5 of ext Country is:  2.1433333333333335\n",
      "Average distance from 5 of reg Food is:  2.6133333333333333\n",
      "Average distance from 5 of ext Food is:  2.316666666666667\n",
      "Average distance from 5 of reg Music is:  2.6333333333333333\n",
      "Average distance from 5 of ext Music is:  1.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Average distance from 5 of all regular is: \", distRegular)\n",
    "print(\"Average distance from 5 of all extended is: \", distExtended)\n",
    "print(\"\")\n",
    "print(\"Average distance from 5 of reg Country is: \", distRegCountry)\n",
    "print(\"Average distance from 5 of ext Country is: \", distExtCountry)\n",
    "print(\"Average distance from 5 of reg Food is: \", distRegFood)\n",
    "print(\"Average distance from 5 of ext Food is: \", distExtFood)\n",
    "print(\"Average distance from 5 of reg Music is: \", distRegMusic)\n",
    "print(\"Average distance from 5 of ext Music is: \", distExtMusic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Agreement on the prefered Antonym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDirectionAgreement(root, allAnswers): #root is 30 and allAnswers is participants x 30\n",
    "    signRoot=np.sign(root)\n",
    "    #print(len(allAnswers)*len(signRoot))\n",
    "    curMean=0\n",
    "    for answer in allAnswers:\n",
    "        flatAnswer = [item for sublist in answer for item in sublist]\n",
    "        signAnswer=np.sign(flatAnswer)\n",
    "        agreeMent=(signRoot*signAnswer+1)/2\n",
    "        #print(agreeMent)\n",
    "        curMean+=np.sum(agreeMent)\n",
    "    mean=curMean/(len(allAnswers)*len(signRoot))    #900\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement of answers on regular pairs: 68.28\n",
      "Agreement of answers on extended pairs: 54.11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root=normalizedRegular#\n",
    "avgAgreementRegular=computeDirectionAgreement(root, answersRegular)*100\n",
    "avgAgreementExtended=computeDirectionAgreement(root, answersExtended)*100\n",
    "print(\"Agreement of answers on regular pairs: %.2f\" % round(avgAgreementRegular, 2))\n",
    "print(\"Agreement of answers on extended pairs: %.2f\" % round(avgAgreementExtended, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute average diviation (absolute values) between Survey and Polar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageAgreement(root, allAnswers): #root is 30 and allAnswers is participants x 30\n",
    "    curMean=0\n",
    "    print(root)\n",
    "    for answer in allAnswers:\n",
    "        flatAnswer = [item for sublist in answer for item in sublist]\n",
    "        agreeMent=abs(root-flatAnswer)\n",
    "        curMean+=np.sum(agreeMent)/len(root)\n",
    "    mean=curMean/len(allAnswers)    \n",
    "    return mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageAgreementCategory(root, allAnswers): #root is 30 and allAnswers is participants x 30\n",
    "    curMean=0\n",
    "    agreeMent=abs(root-np.concatenate(allAnswers))\n",
    "    curMean+=np.sum(agreeMent)\n",
    "    mean=curMean/len(root) \n",
    "    return mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences(a, b):\n",
    "    return sum(i != j for i, j in zip(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMean(answers): #already normalized\n",
    "    flattened=[]\n",
    "    for answer in answers:\n",
    "        flatAnswer = [item for sublist in answer for item in sublist]\n",
    "        flattened.append(flatAnswer)\n",
    "    return np.mean(flattened, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03323543  0.33883835 -0.27097232  0.95404268  0.6293229   0.46637757\n",
      " -0.32862018 -0.71627806  0.79833811  0.00843317  0.5467871   0.3917173\n",
      " -0.01407868 -1.51176115  0.36164316 -1.36653693  0.01491171 -1.25365858\n",
      "  1.04520769  0.34011812 -1.64151259 -0.75053851  0.92575365  0.48055929\n",
      "  1.04555833 -0.85102086  1.19898686  0.30112405 -0.16092154 -0.51395746]\n"
     ]
    }
   ],
   "source": [
    "print(computeMean(answersRegular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Disagreement on the antonym\n",
      "Regular:  6\n",
      "Extended:  13\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Disagreement on the antonym\")\n",
    "\n",
    "\n",
    "normalizedRegularPolar=transformToStandardScore(regularPolar)\n",
    "normalizedExtendedPolar=transformToStandardScore(extendedPolar)\n",
    "\n",
    "#print(answersRegular)\n",
    "\n",
    "meanRegularSurvey=computeMean(answersRegular)\n",
    "meanExtendedSurvey=computeMean(answersExtended)\n",
    "\n",
    "regSignSurvey=np.sign(meanRegularSurvey)\n",
    "extSignSurvey=np.sign(meanExtendedSurvey)\n",
    "regSignPolar=np.sign(normalizedRegularPolar)\n",
    "extSignPolar=np.sign(normalizedExtendedPolar)\n",
    "\n",
    "#print(regSignSurvey,extSignSurvey,regSignPolar,extSignPolar)\n",
    "resultReg=differences(regSignSurvey, regSignPolar)\n",
    "resultExt=differences(extSignSurvey, extSignPolar)\n",
    "\n",
    "print(\"Regular: \",resultReg)\n",
    "print(\"Extended: \",resultExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absDifference(a, b):\n",
    "    return sum(abs(i - j) for i, j in zip(a, b))/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average derivation\n",
      "Regular:  0.6281193594835749\n",
      "Extended:  0.8598132743036366\n"
     ]
    }
   ],
   "source": [
    "print(\"Average derivation\")\n",
    "resultReg=absDifference(meanRegularSurvey, normalizedRegularPolar)\n",
    "resultExt=absDifference(meanExtendedSurvey, normalizedExtendedPolar)\n",
    "\n",
    "print(\"Regular: \",resultReg)\n",
    "print(\"Extended: \",resultExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degreement for regular antonyms from Country:  0.5816666666666667\n",
      "Average degreement for extended antonyms from Country:  0.45666666666666667\n",
      "Average degreement for regular antonyms from Food:  0.765\n",
      "Average degreement for extended antonyms from Food:  0.6733333333333333\n",
      "Average degreement for regular antonyms from Music:  0.7016666666666667\n",
      "Average degreement for extended antonyms from Music:  0.56\n"
     ]
    }
   ],
   "source": [
    "#Country\n",
    "    #Polar\n",
    "regularCountyN=transformToStandardScore(np.array(regularCounty))\n",
    "extendedCountyN=transformToStandardScore(np.array(extendedCounty))\n",
    "    #Survey\n",
    "regAnswerCountryN=transformToStandardScore(np.array(regAnswerCountry))\n",
    "extAnswerCountryN=transformToStandardScore(np.array(extAnswerCountry))\n",
    "    #Direction agreement\n",
    "regCountryAgreement=computeDirectionAgreement(regularCountyN, regAnswerCountryN)\n",
    "print(\"Average agreement for regular antonyms from Country: \", regCountryAgreement)\n",
    "extCountryAgreement=computeDirectionAgreement(extendedCountyN, extAnswerCountryN)\n",
    "print(\"Average agreement for extended antonyms from Country: \", extCountryAgreement)\n",
    "\n",
    "#Food\n",
    "regularFoodN=transformToStandardScore(np.array(regularFood))\n",
    "extendedFoodN=transformToStandardScore(np.array(extendedFood))\n",
    "regAnswerFoodN=transformToStandardScore(np.array(regAnswerFood))\n",
    "extAnswerFoodN=transformToStandardScore(np.array(extAnswerFood))\n",
    "regFoodAgreement=computeDirectionAgreement(regularFoodN, regAnswerFoodN)\n",
    "print(\"Average agreement for regular antonyms from Food: \", regFoodAgreement)\n",
    "extFoodAgreement=computeDirectionAgreement(extendedFoodN, extAnswerFoodN)\n",
    "print(\"Average agreement for extended antonyms from Food: \", extFoodAgreement)\n",
    "\n",
    "#Music\n",
    "regularMusicN=transformToStandardScore(np.array(regularMusic))\n",
    "extendedMusicN=transformToStandardScore(np.array(extendedMusic))\n",
    "regAnswerMusicN=transformToStandardScore(np.array(regAnswerMusic))\n",
    "extAnswerMusicN=transformToStandardScore(np.array(extAnswerMusic))\n",
    "regMusicAgreement=computeDirectionAgreement(regularMusicN, regAnswerMusicN)\n",
    "print(\"Average agreement for regular antonyms from Music: \", regMusicAgreement)\n",
    "extMusicAgreement=computeDirectionAgreement(extendedMusicN, extAnswerMusicN)\n",
    "print(\"Average agreement for extended antonyms from Music: \", extMusicAgreement)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average disagreement for regular antonyms from Country:  0.4\n",
      "Average disagreement for extended antonyms from Country:  0.6\n",
      "Average disagreement for regular antonyms from Food:  0.1\n",
      "Average disagreement for extended antonyms from Food:  0.3\n",
      "Average disagreement for regular antonyms from Music:  0.2\n",
      "Average disagreement for extended antonyms from Music:  0.4\n"
     ]
    }
   ],
   "source": [
    "# Agreeeeeement\n",
    "#Country\n",
    "    #Polar\n",
    "regularCountySign=np.sign(regularCounty)\n",
    "extendedCountySign=np.sign(extendedCounty)\n",
    "    #Survey\n",
    "regAnswerCountrySign=np.sign(computeMean(regAnswerCountry))\n",
    "extAnswerCountrySign=np.sign(computeMean(extAnswerCountry))\n",
    "    #Direction agreement\n",
    "regCountryAgreement=differences(regularCountySign, regAnswerCountrySign)/10\n",
    "print(\"Average disagreement for regular antonyms from Country: \", regCountryAgreement)\n",
    "extCountryAgreement=differences(extendedCountySign, extAnswerCountrySign)/10\n",
    "print(\"Average disagreement for extended antonyms from Country: \", extCountryAgreement)\n",
    "\n",
    "#Food\n",
    "regularFoodSign=np.sign(regularFood)\n",
    "extendedFoodSign=np.sign(extendedFood)\n",
    "regAnswerFoodSign=np.sign(computeMean(regAnswerFood))\n",
    "extAnswerFoodSign=np.sign(computeMean(extAnswerFood))\n",
    "regFoodAgreement=differences(regularFoodSign, regAnswerFoodSign)/10\n",
    "print(\"Average disagreement for regular antonyms from Food: \", regFoodAgreement)\n",
    "extFoodAgreement=differences(extendedFoodSign, extAnswerFoodSign)/10\n",
    "print(\"Average disagreement for extended antonyms from Food: \", extFoodAgreement)\n",
    "\n",
    "#Music\n",
    "regularMusicSign=np.sign(regularMusic)\n",
    "extendedMusicSign=np.sign(extendedMusic)\n",
    "regAnswerMusicSign=np.sign(computeMean(regAnswerMusic))\n",
    "extAnswerMusicSign=np.sign(computeMean(extAnswerMusic))\n",
    "regMusicAgreement=differences(regularMusicSign, regAnswerMusicSign)/10\n",
    "print(\"Average disagreement for regular antonyms from Music: \", regMusicAgreement)\n",
    "extMusicAgreement=differences(extendedMusicSign, extAnswerMusicSign)/10\n",
    "print(\"Average disagreement for extended antonyms from Music: \", extMusicAgreement)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance for regular antonyms from Country:  0.8498117201433834\n",
      "Average distance for extended antonyms from Country:  1.0995306325692316\n",
      "Average distance for regular antonyms from Food:  0.4654151829602993\n",
      "Average distance for extended antonyms from Food:  0.6960719436516506\n",
      "Average distance for regular antonyms from Music:  0.5768128416212231\n",
      "Average distance for extended antonyms from Music:  0.8214764444816864\n",
      "Average distance for all:  0.7515197942379124\n",
      "Average distance for regular:  0.6306799149083019\n",
      "Average distance for extended:  0.872359673567523\n"
     ]
    }
   ],
   "source": [
    "# DISTANCE\n",
    "\n",
    "    #Polar\n",
    "regularCountyN=transformToStandardScore(np.array(regularCounty))\n",
    "extendedCountyN=transformToStandardScore(np.array(extendedCounty))\n",
    "    #Survey\n",
    "regAnswerCountryN=np.mean(transformToStandardScore(np.array(regAnswerCountry)),axis=0)\n",
    "extAnswerCountryN=np.mean(transformToStandardScore(np.array(extAnswerCountry)),axis=0)\n",
    "\n",
    "    #Direction agreement\n",
    "regCountryAgreement=computeAverageAgreementCategory(regularCountyN, regAnswerCountryN)\n",
    "print(\"Average distance for regular antonyms from Country: \", regCountryAgreement)\n",
    "extCountryAgreement=computeAverageAgreementCategory(extendedCountyN, extAnswerCountryN)\n",
    "print(\"Average distance for extended antonyms from Country: \", extCountryAgreement)\n",
    "\n",
    "#Food\n",
    "regularFoodN=transformToStandardScore(np.array(regularFood))\n",
    "extendedFoodN=transformToStandardScore(np.array(extendedFood))\n",
    "regAnswerFoodN=np.mean(transformToStandardScore(np.array(regAnswerFood)),axis=0)\n",
    "extAnswerFoodN=np.mean(transformToStandardScore(np.array(extAnswerFood)),axis=0)\n",
    "regFoodAgreement=computeAverageAgreementCategory(regularFoodN, regAnswerFoodN)\n",
    "print(\"Average distance for regular antonyms from Food: \", regFoodAgreement)\n",
    "extFoodAgreement=computeAverageAgreementCategory(extendedFoodN, extAnswerFoodN)\n",
    "print(\"Average distance for extended antonyms from Food: \", extFoodAgreement)\n",
    "\n",
    "#Music\n",
    "regularMusicN=transformToStandardScore(np.array(regularMusic))\n",
    "extendedMusicN=transformToStandardScore(np.array(extendedMusic))\n",
    "regAnswerMusicN=np.mean(transformToStandardScore(np.array(regAnswerMusic)),axis=0)\n",
    "extAnswerMusicN=np.mean(transformToStandardScore(np.array(extAnswerMusic)),axis=0)\n",
    "regMusicAgreement=computeAverageAgreementCategory(regularMusicN, regAnswerMusicN)\n",
    "print(\"Average distance for regular antonyms from Music: \", regMusicAgreement)\n",
    "extMusicAgreement=computeAverageAgreementCategory(extendedMusicN, extAnswerMusicN)\n",
    "print(\"Average distance for extended antonyms from Music: \", extMusicAgreement)\n",
    "\n",
    "overallDist=(regCountryAgreement+regFoodAgreement+regMusicAgreement+extCountryAgreement+extFoodAgreement+extMusicAgreement)/6\n",
    "regularDist=(regCountryAgreement+regFoodAgreement+regMusicAgreement)/3\n",
    "extendedDist=(extCountryAgreement+extFoodAgreement+extMusicAgreement)/3\n",
    "print(\"Average distance for all: \",overallDist)\n",
    "print(\"Average distance for regular: \",regularDist)\n",
    "print(\"Average distance for extended: \",extendedDist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
